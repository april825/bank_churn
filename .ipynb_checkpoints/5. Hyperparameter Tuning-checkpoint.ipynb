{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "velvet-professor",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:rgb(67, 77, 86);\n",
    "           font-size:300%;\n",
    "           font-style: oblique;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 20px;\">Predicting Bank Churners</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-southeast",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\"background-color:rgb(141, 153, 165);\n",
    "           font-size:250%;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 10px;\">PART 5: MODEL SELECTION</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-tracy",
   "metadata": {},
   "source": [
    "# Summary Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both are series; name of the index is `inc`\n",
    "inc_class = d.groupby('inc').size()\n",
    "print(inc_class)\n",
    "print(inc_class.name)\n",
    "print(inc_class.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both are series; name of the series is `inc`\n",
    "inc_class = d.inc.value_counts(sort=False)\n",
    "print(inc_class)\n",
    "print(inc_class.name)\n",
    "print(inc_class.index.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-computer",
   "metadata": {},
   "source": [
    "# Build Models & Select Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-thunder",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/machine-learning-in-python-step-by-step/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-hospital",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('source/d_v1.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature Dimension: {x.shape}\\t Label Dimension: : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage of Churn for the Full Data: {round(y.sum()/len(y),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-arabic",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Feature Dimension: {x_train.shape}\\t Train Label Dimension: : {y_train.shape}')\n",
    "print(f'Test Feature Dimension: {x_test.shape}\\t Test Label Dimension: : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Percentage of Churn for Train Set: {round(y_train.sum()/len(y_train),2)}\n",
    "Percentage of Churn for Test Set: {round(y_test.sum()/len(y_test),2)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-hollywood",
   "metadata": {},
   "source": [
    "## Spot Check Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-percentage",
   "metadata": {},
   "source": [
    "In this case, we can see that it looks like Support Vector Machines (SVM) has the largest estimated accuracy score at about 0.98 or 98%. We can also create a plot of the model evaluation results and compare the spread and the mean accuracy of each model. There is a population of accuracy measures for each algorithm because each algorithm was evaluated 10 times (via 10 fold-cross validation). A useful way to compare the samples of results for each algorithm is to create a box and whisker plot for each distribution and compare the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='recall')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-sending",
   "metadata": {},
   "source": [
    "## Compare Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-testimony",
   "metadata": {},
   "source": [
    "## Available Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-moderator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "southeast-daily",
   "metadata": {},
   "source": [
    "## Promising Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "# parameters = {\n",
    "#     'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "#     'activation': ['relu', 'tanh', 'logistic'],\n",
    "#     'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "#     'max_iter': [600]  # increased to 400 but took too long\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "# parameters = {'name': 'svm_rbf', 'label': 'SVC (RBF)',\n",
    "#            'classifier':SVC(random_state=88),\n",
    "#            'grid': {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGIT\n",
    "# parameters = {'solver'='saga', 'C'=0.1, 'max_iter'=10000, \n",
    "#              'class_weight'='balanced', 'random_state'=5\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-little",
   "metadata": {},
   "source": [
    "## Template for Evaluating One Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearSVC(C=10, max_iter=100000, class_weight='balanced', random_state=5)\n",
    "# results = []\n",
    "# scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "# kfold = StratifiedKFold(n_splits=2, random_state=1, shuffle=True)\n",
    "# cv_results = cross_validate(\n",
    "#     model, x_train, y_train, cv=kfold, \n",
    "#     scoring=scoring, return_train_score=True)\n",
    "# results.append(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-adult",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-church",
   "metadata": {},
   "source": [
    "### Scaling & Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                stratify=y,random_state = 5)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(random_state=88) # added!\n",
    "adasyn = ADASYN(random_state=88)\n",
    "pipeline = Pipeline([('resampling', adasyn), ('model', model)]) # added!\n",
    "# X_adasyn, y_adasyn = adasyn.fit_resample(X_train_scaled, y_train) # removed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-purple",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "models = [{'name': 'logreg','label': 'Logistic Regression',\n",
    "           'classifier': LogisticRegression(random_state=88),\n",
    "           'grid': {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}},\n",
    "          \n",
    "          {'name': 'knn','label':'K Nearest Neighbors',\n",
    "           'classifier':KNeighborsClassifier(),\n",
    "           'grid': {\"n_neighbors\":np.arange(8)+1}},\n",
    "          \n",
    "          {'name': 'dsc','label': 'Descision Tree', \n",
    "           'classifier': DecisionTreeClassifier(random_state=88),\n",
    "           'grid': {\"max_depth\":np.arange(8)+1}},\n",
    "          \n",
    "          {'name': 'rf', 'label': 'Random Forest',\n",
    "           'classifier': RandomForestClassifier(random_state=88),\n",
    "           'grid': {'n_estimators': [200, 500],'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'max_depth' : [4,5,6,7,8],'criterion' :['gini', 'entropy']}},\n",
    "          \n",
    "          {'name': 'svm_rbf', 'label': 'SVC (RBF)',\n",
    "           'classifier':SVC(random_state=88),\n",
    "           'grid': {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-ranch",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def model_selection(pipeline, name, grid, X_train, y_train, scoring):\n",
    "    \n",
    "    gridsearch_cv=GridSearchCV(pipeline, \n",
    "                               grid,\n",
    "                               cv=5, \n",
    "                               scoring = scoring)\n",
    "    \n",
    "    gridsearch_cv.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    results_dict = {}\n",
    "    \n",
    "    results_dict['classifier_name'] = name    \n",
    "    results_dict['classifier'] = gridsearch_cv.best_estimator_\n",
    "    results_dict['best_params'] = gridsearch_cv.best_params_\n",
    "    results_dict['ROC_AUC'] = gridsearch_cv.best_score_\n",
    "    \n",
    "    return(results_dict)\n",
    "results = []\n",
    "for m in models:    \n",
    "    print(m['name'])    \n",
    "    results.append(fit_first_model(m['classifier'], \n",
    "                                   m['name'],\n",
    "                                   m['grid'],\n",
    "                                   X_train_scaled, \n",
    "                                   y_train, \n",
    "                                   'roc_auc'))      \n",
    "    print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(by='ROC_AUC', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-count",
   "metadata": {},
   "source": [
    "Eager to confirm the performance of the Random Forest Classifier with tuned hyperparameters, I scored the predictive performance of the model on my test set. I was aghast when I saw that my the ROC_AUC score for the test set was only 0.525. In my experience test scores are typically lower than cross-validation scores, and I know that Random Forest can be prone to overfitting, but this was a performance decrease of 38 percent!\n",
    "For good measure, I scored the performances of the remaining four classifiers on the test set. Sure enough, the ROC_AUC test scores were significantly lower than the cross validation ROC_AUC averages. Logistic regression was an exception, performing only slightly better than a random guess on both the validation and test sets.\n",
    "\n",
    "[Source: imbalanced-class-sizes-and-classification-models-a-cautionary-tale-part-2](https://towardsdatascience.com/imbalanced-class-sizes-and-classification-models-a-cautionary-tale-part-2-cf371500d1b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-tennis",
   "metadata": {},
   "source": [
    "Order matters\n",
    "\n",
    "What was going on here? Well, remember that I oversampled with ADASYN before splitting my training data for cross-validation. So, my five-fold validation sets are NOT representative of a distribution in the real world. Rather, they contain “synthetic” data points representative of hard-to-classify observations in the minority class. Therefore, when I scored the model performance on the test set (with the target class proportions indicative of the real-world), the score dropped significantly.\n",
    "\n",
    "Luckily, imbalanced-learn has a Pipeline class that will apply the ADASYN resampling only during the classifier fitting, thus allowing me to avoid some clunky for-loops and manual GridSearchCV.\n",
    "Below is the code to build the pipeline for GridSearchCV hyperparameter tuning on the Random Forest Classifier with oversampling during cross-validation fitting. (Note the class__ prefix in the grid dictionary!)\n",
    "\n",
    "[Source: imbalanced-class-sizes-and-classification-models-a-cautionary-tale-part-2](https://towardsdatascience.com/imbalanced-class-sizes-and-classification-models-a-cautionary-tale-part-2-cf371500d1b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-polymer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-diamond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bearing-holder",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-candy",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparametres for logistic regression\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "grid_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-patrick",
   "metadata": {},
   "source": [
    "## Ridge Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-yeast",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparametres for ridge classifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "model = RidgeClassifier()\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid search\n",
    "grid = dict(alpha=alpha)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-observation",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-beauty",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparametres for KNeighborsClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# define models and parameters\n",
    "model = KNeighborsClassifier()\n",
    "n_neighbors = range(1, 21, 2)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "# define grid search\n",
    "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-jenny",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-scope",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparametres for SVC\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# define model and parameters\n",
    "model = SVC()\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [50, 10, 1.0, 0.1, 0.01]\n",
    "gamma = ['scale']\n",
    "# define grid search\n",
    "grid = dict(kernel=kernel,C=C,gamma=gamma)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-matrix",
   "metadata": {},
   "source": [
    "## Bagged Decision Trees (Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-principal",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-snowboard",
   "metadata": {},
   "source": [
    "The most important parameter for bagged decision trees is the number of trees (n_estimators).\n",
    "\n",
    "Ideally, this should be increased until no further improvement is seen in the model.\n",
    "\n",
    "Good values might be a log scale from 10 to 1,000.\n",
    "\n",
    "n_estimators in [10, 100, 1000]\n",
    "For the full list of hyperparameters, see:\n",
    "\n",
    "sklearn.ensemble.BaggingClassifier API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparameters for BaggingClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# define models and parameters\n",
    "model = BaggingClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-interim",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-bracket",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-stuff",
   "metadata": {},
   "source": [
    "The most important parameter is the number of random features to sample at each split point (`max_features`). You could try a range of integer values, such as `1` to `20`, or `1` to half the number of input features.\n",
    "* `max_features` [`1` to `20`]\n",
    "Alternately, you could try a suite of different default value calculators.\n",
    "* `max_features` in [`sqrt`, `log2`]\n",
    "Another important parameter for random forest is the number of trees (`n_estimators`).\n",
    "Ideally, this should be increased until no further improvement is seen in the model. Good values might be a log scale from `10` to `1000`.\n",
    "* `n_estimators` in [`10`, `100`, `1000`]\n",
    "For the full list of hyperparameters, see:\n",
    "* `sklearn.ensemble.RandomForestClassifier API.`\n",
    "The example below demonstrates grid searching the key hyperparameters for `BaggingClassifier` on a synthetic binary classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparameters for BaggingClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# define models and parameters\n",
    "model = BaggingClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-tribe",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-devil",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-difference",
   "metadata": {},
   "source": [
    "There are some parameter pairings that are important to consider. The first is the `learning rate`, also called shrinkage or eta (`learning_rate`) and the number of trees in the model (`n_estimators`). Both could be considered on a log scale, although in different directions.\n",
    "\n",
    "* `learning_rate` in [`0.001`, `0.01`, `0.1`]\n",
    "* `n_estimators` [`10`, `100`, `1000`]\n",
    "\n",
    "Another pairing is the number of rows or subset of the data to consider for each tree (subsample) and the depth of each tree (`max_depth`). These could be grid searched at a `0.1` and `1` interval respectively, although common values can be tested directly.\n",
    "\n",
    "* `subsample` in [`0.5`, `0.7`, `1.0`]\n",
    "* `max_depth` in [`3`, `7`, `9`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of grid searching key hyperparameters for GradientBoostingClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# define dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\n",
    "# define models and parameters\n",
    "model = GradientBoostingClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "subsample = [0.5, 0.7, 1.0]\n",
    "max_depth = [3, 7, 9]\n",
    "# define grid search\n",
    "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-guest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-junction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-reviewer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-financing",
   "metadata": {},
   "source": [
    "## Rule-Based Algorithm: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-halloween",
   "metadata": {},
   "source": [
    "For our emsemble baseline model we fit the XGBoost Classifier without any hyperparameter tuning. No normalization is necessary since the model is an ensemble of the tree methods. This means that removing outliers should not impact the model's performance that much since XGBoost is not sensitive to monotonic transformations of its features. Let's test this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('source/d_v1.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"GB Classifier Parameters:\")\n",
    "# GradientBoostingClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier_params = GradientBoostingClassifier().get_params()\n",
    "print(f\"\"\"Default Param Values:\n",
    "      `n_estimators`:\\t{GradientBoostingClassifier_params[\"n_estimators\"]} \n",
    "      `max_depth`:\\t{GradientBoostingClassifier_params[\"max_depth\"]}\n",
    "      `learning_rate`:\\t{GradientBoostingClassifier_params[\"learning_rate\"]}\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('Best Parameters: {}\\n'.format(results.best_params_))\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means,stds,results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean,3), round(std*2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5, 50, 100, 250, 500],\n",
    "    'max_depth': [1, 3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(x_train, y_train)\n",
    "yhat = gb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, yhat), 3)\n",
    "precision = round(precision_score(y_test, yhat), 3)\n",
    "recall = round(recall_score(y_test, yhat), 3)\n",
    "f_1 = round(f1_score(y_test, yhat), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(x_train, y_train)\n",
    "yhat = gb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "precision = round(precision_score(y_test, yhat), 4)\n",
    "recall = round(recall_score(y_test, yhat), 4)\n",
    "f_1 = round(f1_score(y_test, yhat), 4)\n",
    "f_2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "print(\"\"\"Gradient Boosting Classifier \n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_fscore_support(y_test, yhat, average='binary', pos_label = 1, beta = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-michigan",
   "metadata": {},
   "source": [
    "In the Data Visualization section, we saw a large number of outliers in the box plots. Let's explore the effects of removing the outliers using various outlier treatment methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier()\n",
    "# parameters = {\n",
    "#     'n_estimators': [5, 50, 250],\n",
    "#     'max_depth': [2, 4, 8, 16, 32, None]\n",
    "# }\n",
    "\n",
    "# cv = GridSearchCV(rf, parameters, cv=5)\n",
    "# cv.fit(tr_features, tr_labels.values.ravel())\n",
    "\n",
    "# print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-colleague",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-outreach",
   "metadata": {},
   "source": [
    "NEED TO SCALE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-warrant",
   "metadata": {},
   "source": [
    "For our linear baseline model we fit the MLP with minimum hyperparameter tuning. SVM is sensitive to outliers as it is a linear model dependentn on a strong assumption of functional form and is therefore sensitive to monotonic transformations of its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('source/d_v1.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature Dimension: {x.shape}\\t Label Dimension: : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train Feature Dimension: {x_train.shape}\\t Train Label Dimension: : {y_train.shape}')\n",
    "print(f'Test Feature Dimension: {x_test.shape}\\t Test Label Dimension: : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Validation of Stratified Train and Test Set:\n",
    "    Percentage of Churn for Train Set: {round(y_train.sum()/len(y_train),2)}\n",
    "    Percentage of Churn for Test Set: {round(y_test.sum()/len(y_test),2)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'max_iter': [100]  # increased to 400 but took too long\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = mlp.get_params()\n",
    "print(f\"\"\"Default Param Values:\n",
    "      `hidden_layer_sizes`:\\t{mlp_params['hidden_layer_sizes']} \n",
    "      `activation`:\\t\\t{mlp_params['activation']}\n",
    "      `learning_rate`:\\t\\t{mlp_params['learning_rate']}\n",
    "      `max_iter`:\\t\\t{mlp_params['max_iter']}\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=300, activation='logistic', learning_rate='adaptive', max_iter=300)\n",
    "mlp.fit(x_train, y_train)\n",
    "yhat = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "precision = round(precision_score(y_test, yhat), 4)\n",
    "recall = round(recall_score(y_test, yhat), 4)\n",
    "f_1 = round(f1_score(y_test, yhat), 4)\n",
    "f_2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "print(\"\"\"Support Vector Machine Classifier \n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = MLPClassifier(hidden_layer_sizes=250, activation='relu', learning_rate='adaptive', max_iter=300)\n",
    "# Support Vector Machine Classifier \n",
    "#       Accuracy:\t  74.78% \n",
    "#       Precision:  37.05%  \n",
    "#       Recall:\t  81.85%  \n",
    "#       F1 Score:\t  51.01%\n",
    "#       F2 Score:\t  65.91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_recall_fscore_support(y_test, yhat, average='binary', pos_label = 1, beta = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-oregon",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(random_state=1)\n",
    "contamination = [int(x) for x in np.arange(start=0.01, stop=0.16, step=0.01)]  # Contamination\n",
    "n_estimators = [int(x) for x in np.arange(start=100, stop=501, step=50)] # Number of trees in random forest [100, 150,..., 500]\n",
    "max_features = [int(x) for x in np.arange(start=1, stop=x_train.shape[1]+1, step=1)] # Number of features to consider at every split\n",
    "bootstrap = [True, False] # Method of selecting samples for training each tree\n",
    "random_grid = {\n",
    "    'contamination': contamination,\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'bootstrap': bootstrap}\n",
    "# ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "scoreFunction = make_scorer(f1_score)\n",
    "\n",
    "# run a RandomizedSearchCV with 4 folds and 25 iterations \n",
    "random_search = RandomizedSearchCV(\n",
    "    iso, \n",
    "    param_distributions = random_grid,\n",
    "    n_iter = 25,\n",
    "    scoring = scoreFunction,\n",
    "    refit = 'recall',\n",
    "    return_train_score = True,\n",
    "    random_state = 1,\n",
    "    verbose = 2,\n",
    "    cv = 4,\n",
    "    n_jobs = -1) \n",
    "\n",
    "# trains and optimizes the model\n",
    "random_search.fit(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('Best Parameters: {}\\n'.format(results.best_params_))\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means,stds,results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean,3), round(std*2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(random_state=123)\n",
    "iso.fit(x_train)\n",
    "parameters = {\n",
    "    'contamination': [0.001, 0.01, 0.025, 0.05, 0.075, 0.1, 0.16]\n",
    "}\n",
    "cv = GridSearchCV(iso, parameters, scoring='recall', cv=5)\n",
    "cv.fit(x_train,)\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gb = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [50, 100, 250],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "cv = RandomizedSearchCV(gb, parameters, cv=5)\n",
    "cv.fit(x_train, y_train)\n",
    "\n",
    "print_results(cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
