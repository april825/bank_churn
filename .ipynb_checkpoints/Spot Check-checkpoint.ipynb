{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bigger-sellers",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "middle-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-audience",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accompanied-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 53 models\n",
      ">0logistic: 0.844 (+/-0.043)\n",
      ">1logistic: 0.844 (+/-0.043)\n",
      ">2logistic: 0.848 (+/-0.034)\n",
      ">3logistic: 0.848 (+/-0.034)\n",
      ">0ridge-0.1: 0.845 (+/-0.038)\n",
      ">1ridge-0.1: 0.845 (+/-0.038)\n",
      ">2ridge-0.1: 0.845 (+/-0.038)\n",
      ">3ridge-0.1: 0.845 (+/-0.038)\n",
      ">0ridge-0.2: 0.845 (+/-0.038)\n",
      ">1ridge-0.2: 0.845 (+/-0.038)\n",
      ">2ridge-0.2: 0.845 (+/-0.038)\n",
      ">3ridge-0.2: 0.845 (+/-0.038)\n",
      ">0ridge-0.3: 0.845 (+/-0.038)\n",
      ">1ridge-0.3: 0.845 (+/-0.038)\n",
      ">2ridge-0.3: 0.845 (+/-0.038)\n",
      ">3ridge-0.3: 0.845 (+/-0.038)\n",
      ">0ridge-0.4: 0.845 (+/-0.038)\n",
      ">1ridge-0.4: 0.845 (+/-0.038)\n",
      ">2ridge-0.4: 0.845 (+/-0.038)\n",
      ">3ridge-0.4: 0.845 (+/-0.038)\n",
      ">0ridge-0.5: 0.845 (+/-0.038)\n",
      ">1ridge-0.5: 0.845 (+/-0.038)\n",
      ">2ridge-0.5: 0.845 (+/-0.038)\n",
      ">3ridge-0.5: 0.845 (+/-0.038)\n",
      ">0ridge-0.6: 0.845 (+/-0.038)\n",
      ">1ridge-0.6: 0.845 (+/-0.038)\n",
      ">2ridge-0.6: 0.845 (+/-0.038)\n",
      ">3ridge-0.6: 0.845 (+/-0.038)\n",
      ">0ridge-0.7: 0.845 (+/-0.038)\n",
      ">1ridge-0.7: 0.845 (+/-0.038)\n",
      ">2ridge-0.7: 0.846 (+/-0.039)\n",
      ">3ridge-0.7: 0.846 (+/-0.039)\n",
      ">0ridge-0.8: 0.845 (+/-0.038)\n",
      ">1ridge-0.8: 0.845 (+/-0.038)\n",
      ">2ridge-0.8: 0.847 (+/-0.039)\n",
      ">3ridge-0.8: 0.847 (+/-0.039)\n",
      ">0ridge-0.9: 0.845 (+/-0.038)\n",
      ">1ridge-0.9: 0.845 (+/-0.038)\n",
      ">2ridge-0.9: 0.847 (+/-0.039)\n",
      ">3ridge-0.9: 0.847 (+/-0.039)\n",
      ">0ridge-1.0: 0.845 (+/-0.038)\n",
      ">1ridge-1.0: 0.845 (+/-0.038)\n",
      ">2ridge-1.0: 0.847 (+/-0.039)\n",
      ">3ridge-1.0: 0.847 (+/-0.039)\n",
      ">0sgd: 0.810 (+/-0.036)\n",
      ">1sgd: 0.806 (+/-0.020)\n",
      ">2sgd: 0.819 (+/-0.061)\n",
      ">3sgd: 0.817 (+/-0.055)\n",
      ">0pa: 0.774 (+/-0.036)\n",
      ">1pa: 0.798 (+/-0.052)\n",
      ">2pa: 0.747 (+/-0.107)\n",
      ">3pa: 0.777 (+/-0.043)\n",
      ">0knn-1: 0.735 (+/-0.028)\n",
      ">1knn-1: 0.710 (+/-0.031)\n",
      ">2knn-1: 0.726 (+/-0.040)\n",
      ">3knn-1: 0.726 (+/-0.040)\n",
      ">0knn-2: 0.716 (+/-0.037)\n",
      ">1knn-2: 0.684 (+/-0.025)\n",
      ">2knn-2: 0.688 (+/-0.026)\n",
      ">3knn-2: 0.688 (+/-0.026)\n",
      ">0knn-3: 0.763 (+/-0.031)\n",
      ">1knn-3: 0.723 (+/-0.045)\n",
      ">2knn-3: 0.741 (+/-0.036)\n",
      ">3knn-3: 0.741 (+/-0.036)\n",
      ">0knn-4: 0.764 (+/-0.040)\n",
      ">1knn-4: 0.712 (+/-0.038)\n",
      ">2knn-4: 0.726 (+/-0.027)\n",
      ">3knn-4: 0.726 (+/-0.027)\n",
      ">0knn-5: 0.784 (+/-0.040)\n",
      ">1knn-5: 0.752 (+/-0.026)\n",
      ">2knn-5: 0.768 (+/-0.035)\n",
      ">3knn-5: 0.768 (+/-0.035)\n",
      ">0knn-6: 0.779 (+/-0.023)\n",
      ">1knn-6: 0.745 (+/-0.036)\n",
      ">2knn-6: 0.755 (+/-0.028)\n",
      ">3knn-6: 0.755 (+/-0.028)\n",
      ">0knn-7: 0.792 (+/-0.031)\n",
      ">1knn-7: 0.756 (+/-0.043)\n",
      ">2knn-7: 0.769 (+/-0.038)\n",
      ">3knn-7: 0.769 (+/-0.038)\n",
      ">0knn-8: 0.783 (+/-0.031)\n",
      ">1knn-8: 0.749 (+/-0.046)\n",
      ">2knn-8: 0.761 (+/-0.045)\n",
      ">3knn-8: 0.761 (+/-0.045)\n",
      ">0knn-9: 0.803 (+/-0.042)\n",
      ">1knn-9: 0.760 (+/-0.037)\n",
      ">2knn-9: 0.772 (+/-0.042)\n",
      ">3knn-9: 0.772 (+/-0.042)\n",
      ">0knn-10: 0.791 (+/-0.037)\n",
      ">1knn-10: 0.755 (+/-0.036)\n",
      ">2knn-10: 0.765 (+/-0.040)\n",
      ">3knn-10: 0.765 (+/-0.040)\n",
      ">0knn-11: 0.803 (+/-0.045)\n",
      ">1knn-11: 0.764 (+/-0.034)\n",
      ">2knn-11: 0.781 (+/-0.043)\n",
      ">3knn-11: 0.781 (+/-0.043)\n",
      ">0knn-12: 0.803 (+/-0.034)\n",
      ">1knn-12: 0.759 (+/-0.044)\n",
      ">2knn-12: 0.780 (+/-0.045)\n",
      ">3knn-12: 0.780 (+/-0.045)\n",
      ">0knn-13: 0.821 (+/-0.030)\n",
      ">1knn-13: 0.767 (+/-0.051)\n",
      ">2knn-13: 0.789 (+/-0.036)\n",
      ">3knn-13: 0.789 (+/-0.036)\n",
      ">0knn-14: 0.812 (+/-0.037)\n",
      ">1knn-14: 0.766 (+/-0.057)\n",
      ">2knn-14: 0.788 (+/-0.036)\n",
      ">3knn-14: 0.788 (+/-0.036)\n",
      ">0knn-15: 0.814 (+/-0.045)\n",
      ">1knn-15: 0.784 (+/-0.049)\n",
      ">2knn-15: 0.800 (+/-0.045)\n",
      ">3knn-15: 0.800 (+/-0.045)\n",
      ">0knn-16: 0.810 (+/-0.041)\n",
      ">1knn-16: 0.775 (+/-0.051)\n",
      ">2knn-16: 0.791 (+/-0.039)\n",
      ">3knn-16: 0.791 (+/-0.039)\n",
      ">0knn-17: 0.825 (+/-0.039)\n",
      ">1knn-17: 0.783 (+/-0.047)\n",
      ">2knn-17: 0.799 (+/-0.027)\n",
      ">3knn-17: 0.799 (+/-0.027)\n",
      ">0knn-18: 0.819 (+/-0.043)\n",
      ">1knn-18: 0.776 (+/-0.047)\n",
      ">2knn-18: 0.796 (+/-0.031)\n",
      ">3knn-18: 0.796 (+/-0.031)\n",
      ">0knn-19: 0.823 (+/-0.035)\n",
      ">1knn-19: 0.774 (+/-0.037)\n",
      ">2knn-19: 0.799 (+/-0.033)\n",
      ">3knn-19: 0.799 (+/-0.033)\n",
      ">0knn-20: 0.827 (+/-0.039)\n",
      ">1knn-20: 0.779 (+/-0.036)\n",
      ">2knn-20: 0.801 (+/-0.035)\n",
      ">3knn-20: 0.801 (+/-0.035)\n",
      ">0cart: 0.793 (+/-0.038)\n",
      ">1cart: 0.787 (+/-0.036)\n",
      ">2cart: 0.804 (+/-0.042)\n",
      ">3cart: 0.792 (+/-0.047)\n",
      ">0extra: 0.734 (+/-0.028)\n",
      ">1extra: 0.715 (+/-0.045)\n",
      ">2extra: 0.704 (+/-0.063)\n",
      ">3extra: 0.724 (+/-0.066)\n",
      ">0svml: 0.846 (+/-0.032)\n",
      ">1svml: 0.846 (+/-0.032)\n",
      ">2svml: 0.841 (+/-0.035)\n",
      ">3svml: 0.841 (+/-0.035)\n",
      ">0svmp: 0.831 (+/-0.040)\n",
      ">1svmp: 0.818 (+/-0.046)\n",
      ">2svmp: 0.810 (+/-0.048)\n",
      ">3svmp: 0.810 (+/-0.048)\n",
      ">0svmr0.1: 0.835 (+/-0.033)\n",
      ">1svmr0.1: 0.820 (+/-0.035)\n",
      ">2svmr0.1: 0.827 (+/-0.034)\n",
      ">3svmr0.1: 0.827 (+/-0.034)\n",
      ">0svmr0.2: 0.842 (+/-0.032)\n",
      ">1svmr0.2: 0.829 (+/-0.033)\n",
      ">2svmr0.2: 0.837 (+/-0.031)\n",
      ">3svmr0.2: 0.837 (+/-0.031)\n",
      ">0svmr0.3: 0.842 (+/-0.032)\n",
      ">1svmr0.3: 0.837 (+/-0.032)\n",
      ">2svmr0.3: 0.840 (+/-0.032)\n",
      ">3svmr0.3: 0.840 (+/-0.032)\n",
      ">0svmr0.4: 0.845 (+/-0.036)\n",
      ">1svmr0.4: 0.837 (+/-0.031)\n",
      ">2svmr0.4: 0.840 (+/-0.035)\n",
      ">3svmr0.4: 0.840 (+/-0.035)\n",
      ">0svmr0.5: 0.845 (+/-0.038)\n",
      ">1svmr0.5: 0.842 (+/-0.034)\n",
      ">2svmr0.5: 0.847 (+/-0.034)\n",
      ">3svmr0.5: 0.847 (+/-0.034)\n",
      ">0svmr0.6: 0.847 (+/-0.040)\n",
      ">1svmr0.6: 0.847 (+/-0.031)\n",
      ">2svmr0.6: 0.847 (+/-0.037)\n",
      ">3svmr0.6: 0.847 (+/-0.037)\n",
      ">0svmr0.7: 0.849 (+/-0.040)\n",
      ">1svmr0.7: 0.847 (+/-0.033)\n",
      ">2svmr0.7: 0.849 (+/-0.039)\n",
      ">3svmr0.7: 0.849 (+/-0.039)\n",
      ">0svmr0.8: 0.849 (+/-0.040)\n",
      ">1svmr0.8: 0.847 (+/-0.040)\n",
      ">2svmr0.8: 0.850 (+/-0.038)\n",
      ">3svmr0.8: 0.850 (+/-0.038)\n",
      ">0svmr0.9: 0.848 (+/-0.044)\n",
      ">1svmr0.9: 0.847 (+/-0.040)\n",
      ">2svmr0.9: 0.849 (+/-0.039)\n",
      ">3svmr0.9: 0.849 (+/-0.039)\n",
      ">0svmr1.0: 0.850 (+/-0.043)\n",
      ">1svmr1.0: 0.846 (+/-0.040)\n",
      ">2svmr1.0: 0.849 (+/-0.038)\n",
      ">3svmr1.0: 0.849 (+/-0.038)\n",
      ">0bayes: 0.816 (+/-0.035)\n",
      ">1bayes: 0.816 (+/-0.035)\n",
      ">2bayes: 0.816 (+/-0.035)\n",
      ">3bayes: 0.816 (+/-0.035)\n",
      ">0ada: 0.839 (+/-0.031)\n",
      ">1ada: 0.839 (+/-0.031)\n",
      ">2ada: 0.839 (+/-0.031)\n",
      ">3ada: 0.839 (+/-0.031)\n",
      ">0bag: 0.862 (+/-0.036)\n",
      ">1bag: 0.864 (+/-0.040)\n",
      ">2bag: 0.861 (+/-0.038)\n",
      ">3bag: 0.856 (+/-0.041)\n",
      ">0rf: 0.864 (+/-0.035)\n",
      ">1rf: 0.865 (+/-0.035)\n",
      ">2rf: 0.866 (+/-0.037)\n",
      ">3rf: 0.863 (+/-0.041)\n",
      ">0et: 0.860 (+/-0.035)\n",
      ">1et: 0.859 (+/-0.034)\n",
      ">2et: 0.865 (+/-0.033)\n",
      ">3et: 0.858 (+/-0.038)\n",
      ">0gbm: 0.862 (+/-0.045)\n",
      ">1gbm: 0.867 (+/-0.044)\n",
      ">2gbm: 0.866 (+/-0.045)\n",
      ">3gbm: 0.865 (+/-0.044)\n",
      "\n",
      "Rank=1, Name=1gbm, Score=0.867 (+/- 0.044)\n",
      "Rank=2, Name=2gbm, Score=0.866 (+/- 0.045)\n",
      "Rank=3, Name=2rf, Score=0.866 (+/- 0.037)\n",
      "Rank=4, Name=3gbm, Score=0.865 (+/- 0.044)\n",
      "Rank=5, Name=2et, Score=0.865 (+/- 0.033)\n",
      "Rank=6, Name=1rf, Score=0.865 (+/- 0.035)\n",
      "Rank=7, Name=0rf, Score=0.864 (+/- 0.035)\n",
      "Rank=8, Name=1bag, Score=0.864 (+/- 0.040)\n",
      "Rank=9, Name=3rf, Score=0.863 (+/- 0.041)\n",
      "Rank=10, Name=0gbm, Score=0.862 (+/- 0.045)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "\treturn make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "\t# linear models\n",
    "\tmodels['logistic'] = LogisticRegression()\n",
    "\talpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor a in alpha:\n",
    "\t\tmodels['ridge-'+str(a)] = RidgeClassifier(alpha=a)\n",
    "\tmodels['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\tmodels['pa'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "\t# non-linear models\n",
    "\tn_neighbors = range(1, 21)\n",
    "\tfor k in n_neighbors:\n",
    "\t\tmodels['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['extra'] = ExtraTreeClassifier()\n",
    "\tmodels['svml'] = SVC(kernel='linear')\n",
    "\tmodels['svmp'] = SVC(kernel='poly')\n",
    "\tc_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor c in c_values:\n",
    "\t\tmodels['svmr'+str(c)] = SVC(C=c)\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\t# ensemble models\n",
    "\tn_trees = 100\n",
    "\tmodels['ada'] = AdaBoostClassifier(n_estimators=n_trees)\n",
    "\tmodels['bag'] = BaggingClassifier(n_estimators=n_trees)\n",
    "\tmodels['rf'] = RandomForestClassifier(n_estimators=n_trees)\n",
    "\tmodels['et'] = ExtraTreesClassifier(n_estimators=n_trees)\n",
    "\tmodels['gbm'] = GradientBoostingClassifier(n_estimators=n_trees)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# no transforms pipeline\n",
    "def pipeline_none(model):\n",
    "\treturn model\n",
    "\n",
    "# standardize transform pipeline\n",
    "def pipeline_standardize(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# normalize transform pipeline\n",
    "def pipeline_normalize(model):\n",
    "\tsteps = list()\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# standardize and normalize pipeline\n",
    "def pipeline_std_norm(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric, pipe_func):\n",
    "\t# create the pipeline\n",
    "\tpipeline = pipe_func(model)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric, pipe_func):\n",
    "\tscores = None\n",
    "\ttry:\n",
    "\t\twith warnings.catch_warnings():\n",
    "\t\t\twarnings.filterwarnings(\"ignore\")\n",
    "\t\t\tscores = evaluate_model(X, y, model, folds, metric, pipe_func)\n",
    "\texcept:\n",
    "\t\tscores = None\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, pipe_funcs, folds=10, metric='accuracy'):\n",
    "\tresults = dict()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate model under each preparation function\n",
    "\t\tfor i in range(len(pipe_funcs)):\n",
    "\t\t\t# evaluate the model\n",
    "\t\t\tscores = robust_evaluate_model(X, y, model, folds, metric, pipe_funcs[i])\n",
    "\t\t\t# update name\n",
    "\t\t\trun_name = str(i) + name\n",
    "\t\t\t# show process\n",
    "\t\t\tif scores is not None:\n",
    "\t\t\t\t# store a result\n",
    "\t\t\t\tresults[run_name] = scores\n",
    "\t\t\t\tmean_score, std_score = mean(scores), std(scores)\n",
    "\t\t\t\tprint('>%s: %.3f (+/-%.3f)' % (run_name, mean_score, std_score))\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint('>%s: error' % run_name)\n",
    "\treturn results\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "\t# check for no results\n",
    "\tif len(results) == 0:\n",
    "\t\tprint('no results')\n",
    "\t\treturn\n",
    "\t# determine how many results to summarize\n",
    "\tn = min(top_n, len(results))\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\t# retrieve the top n for summarization\n",
    "\tnames = [x[0] for x in mean_scores[:n]]\n",
    "\tscores = [results[x[0]] for x in mean_scores[:n]]\n",
    "\t# print the top n\n",
    "\tprint()\n",
    "\tfor i in range(n):\n",
    "\t\tname = names[i]\n",
    "\t\tmean_score, std_score = mean(results[name]), std(results[name])\n",
    "\t\tprint('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "\t# boxplot for the top n\n",
    "\tpyplot.boxplot(scores, labels=names)\n",
    "\t_, labels = pyplot.xticks()\n",
    "\tpyplot.setp(labels, rotation=90)\n",
    "\tpyplot.savefig('spotcheck.png')\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "# get model list\n",
    "models = define_models()\n",
    "# define transform pipelines\n",
    "pipelines = [pipeline_none, pipeline_standardize, pipeline_normalize, pipeline_std_norm]\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models, pipelines)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-johnston",
   "metadata": {},
   "source": [
    "# Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sweet-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns X and y elements\n",
    "def load_dataset():\n",
    "    d = pd.read_csv('source/d_num.csv')\n",
    "    d_values = d.values\n",
    "    return d_values[:,1:], d_values[:,:1].ravel()\n",
    "\n",
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "\t# linear models\n",
    "#     models['logistic'] = LogisticRegression(solver='saga', max_iter=10000, class_weight='balanced', random_state=5)\n",
    "        \n",
    "    # non-linear model\n",
    "    iter_times = [500, 1000, 2000]\n",
    "    for i in iter_times:\n",
    "        models['MLP'] = MLPClassifier(max_iter=i, random_state=5)\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['extra'] = ExtraTreeClassifier()\n",
    "\tmodels['svmp'] = SVC(kernel='poly')\n",
    "\tc_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor c in c_values:\n",
    "\t\tmodels['svmr'+str(c)] = SVC(C=c)\n",
    "        \n",
    "\t# ensemble models\n",
    "\tn_trees = [10, 30,50,100]\n",
    "\tmodels['ada'] = AdaBoostClassifier(n_estimators=n_trees, n_jobs=-1, random_state=5)\n",
    "\tmodels['bag'] = BaggingClassifier(n_estimators=n_trees, n_jobs=-1, random_state=5)\n",
    "\tmodels['rf'] = RandomForestClassifier(n_estimators=n_trees, n_jobs=-1, random_state=5)\n",
    "\tmodels['et'] = ExtraTreesClassifier(n_estimators=n_trees, n_jobs=-1, random_state=5)\n",
    "\tmodels['gbm'] = GradientBoostingClassifier(n_estimators=n_trees, n_jobs=-1, random_state=5)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# no transforms pipeline\n",
    "def pipeline_none(model):\n",
    "\treturn model\n",
    "\n",
    "# standardize transform pipeline\n",
    "def pipeline_standardize(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# normalize transform pipeline\n",
    "def pipeline_normalize(model):\n",
    "\tsteps = list()\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# standardize and normalize pipeline\n",
    "def pipeline_std_norm(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric, pipe_func):\n",
    "\t# create the pipeline\n",
    "\tpipeline = pipe_func(model)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring=metric, cv=folds, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X, y, model, folds, metric, pipe_func):\n",
    "\tscores = None\n",
    "\ttry:\n",
    "\t\twith warnings.catch_warnings():\n",
    "\t\t\twarnings.filterwarnings(\"ignore\")\n",
    "\t\t\tscores = evaluate_model(X, y, model, folds, metric, pipe_func)\n",
    "\texcept:\n",
    "\t\tscores = None\n",
    "\treturn scores\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, pipe_funcs, folds=10, metric='recall'):\n",
    "\tresults = dict()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate model under each preparation function\n",
    "\t\tfor i in range(len(pipe_funcs)):\n",
    "\t\t\t# evaluate the model\n",
    "\t\t\tscores = robust_evaluate_model(X, y, model, folds, metric, pipe_funcs[i])\n",
    "\t\t\t# update name\n",
    "\t\t\trun_name = str(i) + name\n",
    "\t\t\t# show process\n",
    "\t\t\tif scores is not None:\n",
    "\t\t\t\t# store a result\n",
    "\t\t\t\tresults[run_name] = scores\n",
    "\t\t\t\tmean_score, std_score = mean(scores), std(scores)\n",
    "\t\t\t\tprint('>%s: %.3f (+/-%.3f)' % (run_name, mean_score, std_score))\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint('>%s: error' % run_name)\n",
    "\treturn results\n",
    "\n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "\t# check for no results\n",
    "\tif len(results) == 0:\n",
    "\t\tprint('no results')\n",
    "\t\treturn\n",
    "\t# determine how many results to summarize\n",
    "\tn = min(top_n, len(results))\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\t# retrieve the top n for summarization\n",
    "\tnames = [x[0] for x in mean_scores[:n]]\n",
    "\tscores = [results[x[0]] for x in mean_scores[:n]]\n",
    "\t# print the top n\n",
    "\tprint()\n",
    "\tfor i in range(n):\n",
    "\t\tname = names[i]\n",
    "\t\tmean_score, std_score = mean(results[name]), std(results[name])\n",
    "\t\tprint('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "\t# boxplot for the top n\n",
    "\tpyplot.boxplot(scores, labels=names)\n",
    "\t_, labels = pyplot.xticks()\n",
    "\tpyplot.setp(labels, rotation=90)\n",
    "\tpyplot.savefig('spotcheck.png')\n",
    "\n",
    "# load dataset\n",
    "X, y = load_dataset()\n",
    "# get model list\n",
    "models = define_models()\n",
    "# define transform pipelines\n",
    "pipelines = [pipeline_none, pipeline_standardize, pipeline_normalize, pipeline_std_norm]\n",
    "# evaluate models\n",
    "results = evaluate_models(X, y, models, pipelines)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
