{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separate-christian",
   "metadata": {},
   "source": [
    "<a id='4.4.1.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Train-Test Split</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x, y = d[:,1:], d[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secondary-wildlife",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension: (10127, 26)\t Label Dimension: : (10127,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature Dimension: {x.shape}\\t Label Dimension: : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "capable-behalf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Churn for the Full Data: 16.07%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of Churn for the Full Data: {round(y.sum()/len(y),4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "honey-processing",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Feature Dimension: (8101, 26)\t Train Label Dimension: : (8101,)\n",
      "Test Feature Dimension: (2026, 26)\t Test Label Dimension: : (2026,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Feature Dimension: {x_train.shape}\\t Train Label Dimension: : {y_train.shape}')\n",
    "print(f'Test Feature Dimension: {x_test.shape}\\t Test Label Dimension: : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "optimum-magnitude",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Churn for Train Set: 16.07%\n",
      "Percentage of Churn for Test Set: 16.04%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Percentage of Churn for Train Set: {round(y_train.sum()/len(y_train),4)*100}%\n",
    "Percentage of Churn for Test Set: {round(y_test.sum()/len(y_test),4)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-chemical",
   "metadata": {},
   "source": [
    "<a id='4.4.3'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Logistic Regression</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-demand",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/selectively-scale-numerical-input-variables-for-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-dakota",
   "metadata": {},
   "source": [
    "<a id='4.4.4'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Model Attributes</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promising-litigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Logistic Regression Parameters:\")\n",
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "persistent-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Param Values:\n",
      "  `C`:\t\t1.0 \n",
      "  `solver`:\tlbfgs\n",
      "  `max_iter`:\t100\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_params = LogisticRegression().get_params()\n",
    "print(f\"\"\"Default Param Values:\n",
    "  `C`:\\t\\t{LogisticRegression_params[\"C\"]} \n",
    "  `solver`:\\t{LogisticRegression_params[\"solver\"]}\n",
    "  `max_iter`:\\t{LogisticRegression_params[\"max_iter\"]}\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-surprise",
   "metadata": {},
   "source": [
    "<a id='4.4.5'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Model Fitting & Evaluation - Baseline</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-bulletin",
   "metadata": {},
   "source": [
    "Notes on L1 and L2 regularization:\n",
    "> *Inroducing a penalty to the sum of the weights means that the model has to \"distribute\" its weights optimally, so naturally most of this \"resource\" will go to the simple features that explain most of the variance, with complex features getting small or zero weights.*\n",
    "\n",
    "[Edden Gerber, *Comment on a Medium Article*](https://medium.com/@edden.gerber/thanks-for-the-article-1003ad7478b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "democratic-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the modeling pipeline\n",
    "model = LogisticRegression(solver='saga', class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "scaler = MinMaxScaler()\n",
    "pipeline = Pipeline([('s',scaler),('m',model)])\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model\n",
    "m_scores = cross_validate(\n",
    "    pipeline, x_train, y_train, \n",
    "    scoring=['accuracy','precision','recall','f1'], cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "committed-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on Validation Set\n",
      "      Fit Time:\t  0.18 (0.03)\n",
      "      Score Time:  0.01 (0.01)\n",
      "      Accuracy:\t  84.68 (0.01)% \n",
      "      Precision:  51.54 (0.02)%  \n",
      "      Recall:\t  83.67 (0.04)%  \n",
      "      F1 Score:\t  63.73 (0.02)%\n"
     ]
    }
   ],
   "source": [
    "# summarize the results\n",
    "fit_time = round(mean(m_scores['fit_time']), 4)\n",
    "fit_time_sd = round(std(m_scores['fit_time']), 4)\n",
    "score_time = round(mean(m_scores['score_time']), 4)\n",
    "score_time_sd = round(std(m_scores['score_time']), 4)\n",
    "accuracy = round(mean(m_scores['test_accuracy']), 4)\n",
    "accuracy_sd = round(std(m_scores['test_accuracy']), 4)\n",
    "precision = round(mean(m_scores['test_precision']), 4)\n",
    "precision_sd = round(std(m_scores['test_precision']), 4)\n",
    "recall = round(mean(m_scores['test_recall']), 4)\n",
    "recall_sd = round(std(m_scores['test_recall']), 4)\n",
    "f1 = round(mean(m_scores['test_f1']), 4)\n",
    "f1_sd = round(std(m_scores['test_f1']), 4)\n",
    "\n",
    "print(\"\"\"Logistic Regression on Validation Set\n",
    "      Fit Time:\\t  %.2f (%.2f)\n",
    "      Score Time:  %.2f (%.2f)\n",
    "      Accuracy:\\t  %.2f (%.2f)%% \n",
    "      Precision:  %.2f (%.2f)%%  \n",
    "      Recall:\\t  %.2f (%.2f)%%  \n",
    "      F1 Score:\\t  %.2f (%.2f)%%\"\"\" \n",
    "      % (fit_time, fit_time_sd,\n",
    "         score_time, score_time_sd,\n",
    "         accuracy*100, accuracy_sd,\n",
    "         precision*100, precision_sd,\n",
    "         recall*100, recall_sd,\n",
    "         f1*100, f1_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "approximate-sociology",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# model = LogisticRegression(solver='saga', class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "# Logistic Regression on Validation Set\n",
    "#       Fit Time:\t  0.18 (0.03)\n",
    "#       Score Time:  0.01 (0.01)\n",
    "#       Accuracy:\t  84.68 (0.01)% \n",
    "#       Precision:  51.54 (0.02)%  \n",
    "#       Recall:\t  83.67 (0.04)%  \n",
    "#       F1 Score:\t  63.73 (0.02)%\n",
    "\n",
    "# model = LogisticRegression(solver='saga', class_weight='balanced', C=0.01, max_iter=10000, random_state=1)\n",
    "# Logistic Regression on Validation Set\n",
    "#       Fit Time:\t  0.18 (0.02)\n",
    "#       Score Time:  0.01 (0.00)\n",
    "#       Accuracy:\t  80.66 (0.01)% \n",
    "#       Precision:  44.24 (0.02)%  \n",
    "#       Recall:\t  78.09 (0.05)%  \n",
    "#       F1 Score:\t  56.45 (0.02)%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "crazy-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test dataset\n",
    "model.fit(x_train, y_train)\n",
    "yhat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions on test dataset\n",
    "accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "precision = round(precision_score(y_test, yhat), 4)\n",
    "recall = round(recall_score(y_test, yhat), 4)\n",
    "f_1 = round(f1_score(y_test, yhat), 4)\n",
    "f_2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "print(\"\"\"Logistic Regression on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "processed-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(solver='saga', class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "# Logistic Regression on Test Set\n",
    "#       Accuracy:\t  79.12% \n",
    "#       Precision:  42.17%  \n",
    "#       Recall:\t  81.23%  \n",
    "#       F1 Score:\t  55.52%\n",
    "#       F2 Score:\t  68.54%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "collective-brother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1339  362]\n",
      " [  61  264]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "unlikely-municipality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.79      0.86      1701\n",
      "         1.0       0.42      0.81      0.56       325\n",
      "\n",
      "    accuracy                           0.79      2026\n",
      "   macro avg       0.69      0.80      0.71      2026\n",
      "weighted avg       0.87      0.79      0.81      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Use RandomSearchCV to tune parameters for ISO\n",
    "\n",
    "# Takes a while to compute and uses a lot of CPU \n",
    "# https://stats.stackexchange.com/questions/186182/a-way-to-maintain-classifiers-recall-while-improving-precision\n",
    "#model\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "print('Running RandomizedSearchCV')\n",
    "# default IsolationForest but set random_state = 0 to keep consistent results\n",
    "iso = IsolationForest(random_state=123)\n",
    "\n",
    "# Implement RandomSearchCV\n",
    "\n",
    "# Number of trees in random forest [100, 150,..., 500]\n",
    "n_estimators = [int(x) for x in np.arange(start = 100, stop = 501, step = 50)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.arange(start = 1, stop = x_train.shape[1]+1, step = 1)]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "scoreFunction = {\"recall\": \"recall\"}\n",
    "\n",
    "# run a RandomizedSearchCV with 3 folds and 25 iterations \n",
    "random_search = RandomizedSearchCV(iso,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   n_iter = 25,\n",
    "                                   scoring = scoreFunction,               \n",
    "                                   refit = \"recall\",\n",
    "                                   return_train_score = False,\n",
    "                                   random_state = 0,\n",
    "                                   verbose = 2,\n",
    "                                   cv = 5,\n",
    "                                   n_jobs = -1) \n",
    "\n",
    "# trains and optimizes the model\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "print('Finished RandomizedSearchCV ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Improved Model from RandomizedSearchCV\")\n",
    "iso_search = random_search.best_estimator_\n",
    "iso_search.set_params(random_state=0)\n",
    "print(iso_search.get_params())\n",
    "evaluate(iso_search,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-shaft",
   "metadata": {},
   "source": [
    "<a id='7.1.2.1'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Gradient Boosting Classifier\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-cricket",
   "metadata": {},
   "source": [
    "<a id='7.1.2.2'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Logistic Regression\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-recipe",
   "metadata": {},
   "source": [
    "<a id='7.2'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        One-Class SVM\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-patrick",
   "metadata": {},
   "source": [
    "The SVM algorithm originally developed for binary classification also has a use for detecting outliers. When modeling one class, the algorithm calculates the probability density function of the majority class and marks exmples on both extremes of the function as outliers. The class provides the argument `nu` which is equivalent of the percentage of outliers just like the argument `contamination` in `iso()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-metallic",
   "metadata": {},
   "source": [
    "The main difference from a standard SVM is that One-Class SVM takes an unsupervised approach as it does not provide normal hyperparameters for tuning the margin like C. Instead, the argument `nu` is used to control the sensitivity of the support vectors and define the percentage of outliers just like the argument `contamination` in `iso()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-check",
   "metadata": {},
   "source": [
    "<a id='7.2.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Fit on All Classes\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-rating",
   "metadata": {},
   "source": [
    "<h2 style='font-size:150%;'>\n",
    "    Train-Test Split\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "numerical-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "little-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dynamic-income",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8101, 26) (8101,)\n",
      "(2026, 26) (2026,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-robinson",
   "metadata": {},
   "source": [
    "<h2 style='font-size:150%;'>\n",
    "    Model Attributes\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "collectible-strain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'nu': 0.5,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneClassSVM().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "norman-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "ocsvm = OneClassSVM(nu=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "played-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = ocsvm.fit_predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cloudy-damage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "specific-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8101, 26) (8101,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "primary-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8022, 26) (8022,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_train[yhat!=-1,:], y_train[yhat!=-1]\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cheap-camera",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990248117516356"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)/8101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cheap-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2026,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-messenger",
   "metadata": {},
   "source": [
    "<a id='7.2.1.1'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Gradient Boosting Classifier\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rd.seed(1)\n",
    "gb = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "gb.fit(x_train, y_train)\n",
    "yhat = gb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, yhat), 3)\n",
    "precision = round(precision_score(y_test, yhat), 3)\n",
    "recall = round(recall_score(y_test, yhat), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "guilty-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.seed(1)\n",
    "gb = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "gb.fit(x_train, y_train)\n",
    "yhat = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "sporting-hamilton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier on Test Set\n",
      "      Accuracy:\t  97.98% \n",
      "      Precision:  94.10%  \n",
      "      Recall:\t  93.23%  \n",
      "      F1 Score:\t  93.66%\n",
      "      F2 Score:\t  93.40%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions on test dataset\n",
    "accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "precision = round(precision_score(y_test, yhat), 4)\n",
    "recall = round(recall_score(y_test, yhat), 4)\n",
    "f_1 = round(f1_score(y_test, yhat), 4)\n",
    "f_2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "print(\"\"\"Gradient Boosting Classifier on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-retention",
   "metadata": {},
   "source": [
    "***Note:***\n",
    "\n",
    "* The baseline model yielded:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.972 / Precision: 0.93 / Recall: 0.895\n",
    "* `iso()` with 5% contamination yielded results slightly better results overall:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.974 / Precision: 0.939 / Recall: 0.898\n",
    "* `LocalOutlierFactor()` with no hyperparameter tuning:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.974 / Precision: 0.939 / Recall: 0.898\n",
    "* `OneClassSVM()` with nu = 0.05, 0.03, 0.01:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.971 / Precision: 0.929 / Recall: 0.886\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.972 / Precision: 0.935 / Recall: 0.886\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.973 / Precision: 0.936 / Recall: 0.895"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-negative",
   "metadata": {},
   "source": [
    "<a id='7.1.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Fit on Majority Class\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-fields",
   "metadata": {},
   "source": [
    "ignore the task of discrimination and instead focus on deviations from normal or what is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-consideration",
   "metadata": {},
   "source": [
    "This solution has proven to be especially useful when the minority class lack any structure, being predominantly composed of small disjuncts or noisy instances.\n",
    "\n",
    "[Page 139, Learning from Imbalanced Data Sets, 2018.](https://www.amazon.com/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-edgar",
   "metadata": {},
   "source": [
    "One must remember that the advantages of one-class classifiers come at a price of discarding all of available information about the majority class. Therefore, this solution should be used carefully and may not fit some specific applications.\n",
    "\n",
    "[Page 140, Learning from Imbalanced Data Sets, 2018.](https://www.amazon.com/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x, y = d[:,1:], d[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit only on existing customers (majority class)\n",
    "x_train = x_train[y_train==0]\n",
    "y_train = y_train[y_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark inliers = 1\n",
    "y_train[y_train==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark inliers = 1, outliers = -1\n",
    "y_test[y_test==1] = -1\n",
    "y_test[y_test==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine shape\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-fisher",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Spearman's Rank Correlation</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-variance",
   "metadata": {},
   "source": [
    "This statistical method quantifies the degree to which ranked variables are associated by a monotonic function, meaning an increasing or decreasing relationship. As a statistical hypothesis test, the method assumes that the samples are uncorrelated (fail to reject H0).\n",
    "\n",
    "[Source: Machine Learning Mastery - How to Calculate Nonparametric Rank Correlation in Python](https://machinelearningmastery.com/how-to-calculate-nonparametric-rank-correlation-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "heavy-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_churn = d.rank().corr(method='spearman')['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "recorded-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient Using Spearman's Rank Correlation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "churn                1.00\n",
       "contr_ct_r12         0.19\n",
       "mo_inactive_r12      0.17\n",
       "opentobuy_avg_r12    0.03\n",
       "dependents           0.02\n",
       "marstat_Single       0.02\n",
       "age                  0.02\n",
       "mo_on_book           0.02\n",
       "card_Platinum        0.01\n",
       "marstat_Unknown      0.01\n",
       "educ                 0.01\n",
       "card_Gold            0.01\n",
       "card_Blue            0.00\n",
       "marstat_Divorced     0.00\n",
       "tx_amt_pertx_r12    -0.01\n",
       "card_Silver         -0.01\n",
       "inc                 -0.02\n",
       "marstat_Married     -0.02\n",
       "gender              -0.04\n",
       "credlim_avg_r12     -0.05\n",
       "chng_tx_amt_q4_q1   -0.10\n",
       "prod_ct             -0.15\n",
       "tx_amt_r12          -0.22\n",
       "utilratio_avg       -0.24\n",
       "revbal_avg_r12      -0.24\n",
       "chng_tx_ct_q4_q1    -0.31\n",
       "tx_ct_r12           -0.38\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Correlation Coefficient Using Spearman\\'s Rank Correlation')\n",
    "spearman_churn.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "individual-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null: the two variables are correlated\n",
    "reject_h0 = {}\n",
    "failtoreject_h0 = {}\n",
    "for i in d.rank().columns:\n",
    "    coef, p = spearmanr(d[i], d['churn'])\n",
    "    if p >= 0.05:\n",
    "        failtoreject_h0[i] = [round(coef,3), round(p,3)]\n",
    "    else:\n",
    "        reject_h0[i] = [round(coef,3), round(p,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "enormous-monkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following variables are likely correlated to `churn`. We can safely reject H0: \n",
      "\n",
      "Variable             Coef            p-value   \n",
      "churn                1.0             0.0       \n",
      "gender               -0.037          0.0       \n",
      "dependents           0.021           0.035     \n",
      "prod_ct              -0.15           0.0       \n",
      "mo_inactive_r12      0.172           0.0       \n",
      "contr_ct_r12         0.189           0.0       \n",
      "revbal_avg_r12       -0.241          0.0       \n",
      "credlim_avg_r12      -0.051          0.0       \n",
      "opentobuy_avg_r12    0.028           0.006     \n",
      "utilratio_avg        -0.24           0.0       \n",
      "tx_amt_r12           -0.224          0.0       \n",
      "tx_ct_r12            -0.376          0.0       \n",
      "chng_tx_amt_q4_q1    -0.102          0.0       \n",
      "chng_tx_ct_q4_q1     -0.312          0.0       \n",
      "marstat_Married      -0.024          0.017     \n"
     ]
    }
   ],
   "source": [
    "print(f'The following variables are likely correlated to `churn`. We can safely reject H0: \\n')\n",
    "print(\"{:<20} {:<15} {:<10}\".format('Variable', 'Coef', 'p-value'))\n",
    "for k,v in reject_h0.items():\n",
    "    print(\"{:<20} {:<15} {:<10}\".format(k,v[0], v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# load data\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()\n",
    "\n",
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "# create scaler\n",
    "scaler = QuantileTransformer()\n",
    "\n",
    "# fit scaler on data\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# apply transform\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# inverse transform\n",
    "# inverse = scaler.inverse_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-reputation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def result_summary(names, results):\n",
    "#     # create a dataframe of results\n",
    "#     d_results = pd.DataFrame()\n",
    "#     for i in np.arange(len(names)):\n",
    "#         results_metric = []\n",
    "#         results_mean = []\n",
    "#         results_std = []\n",
    "#         for k,v in results[i].items():\n",
    "#             results_metric.append(k)\n",
    "#             results_mean.append(np.round(np.mean(v),3))\n",
    "#             results_std.append(np.round(np.std(v),3))\n",
    "#         df = pd.DataFrame(\n",
    "#                 list(zip(results_metric, results_mean, results_std, [names[i] for ct in np.arange(len(cv_results))])), \n",
    "#                 columns=['metric', 'mean', 'std', 'mod'])\n",
    "#         df = df.set_index(['mod','metric']).stack().unstack([1,2])\n",
    "#         d_results = pd.concat([d_results, df])\n",
    "        \n",
    "#     # return a dataframe of results\n",
    "#     return(d_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
