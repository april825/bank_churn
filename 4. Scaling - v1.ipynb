{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "committed-adapter",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:rgb(67, 77, 86);\n",
    "           font-size:300%;\n",
    "           font-style: oblique;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 20px;\">Predicting Bank Churners</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-berkeley",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\"background-color:rgb(141, 153, 165);\n",
    "           font-size:250%;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 10px;\">Chapter 4. Scaling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-rhythm",
   "metadata": {},
   "source": [
    "<a id='1.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Mission</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-development",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <blockquote cite='https://www.kaggle.com/sakshigoyal7/credit-card-customers/tasks?taskId=2729'>\n",
    "        <p style='font-size:110%;\n",
    "                  color:hsl(208, 12%, 30%);'><i>Our top priority in this business problem is to identify customers who are getting churned. Even if we predict non-churning customers as churned, it won't harm our business. But predicting churning customers as non-churning will do. So recall needs to be higher. Till now, I have managed to get a recall of 62%.</i></p>\n",
    "    </blockquote>\n",
    "    <figcaption>â€”Sakshi Goyal, <cite>Credit Card Customers, Kaggle</cite></figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-updating",
   "metadata": {},
   "source": [
    "<a id='4.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Libraries</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nuclear-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import copy\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# statistics\n",
    "from scipy import stats\n",
    "from scipy.stats import (\n",
    "    pearsonr, spearmanr, kendalltau,\n",
    "    chi2_contingency, f_oneway)\n",
    "\n",
    "# machine learning prep\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer)\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_validate, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV)\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, fbeta_score, auc, roc_auc_score,\n",
    "    precision_recall_curve, plot_precision_recall_curve, average_precision_score, precision_recall_fscore_support,\n",
    "    classification_report, precision_recall_fscore_support, confusion_matrix, SCORERS)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import (SVC, LinearSVC) # remove SVC later if not used\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, RandomForestClassifier, IsolationForest)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# saving\n",
    "import os\n",
    "\n",
    "# multiprocessing\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# display settings\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "written-insert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "/* CSS styles for pandas dataframe */\n",
       ".dataframe th {\n",
       "    font-size: 16px;\n",
       "}\n",
       ".dataframe td {\n",
       "    font-size: 14px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* CSS styles for pandas dataframe */\n",
    ".dataframe th {\n",
    "    font-size: 16px;\n",
    "}\n",
    ".dataframe td {\n",
    "    font-size: 14px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fallen-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_options('precision', 3)\n",
    "# pd.set_options('min_rows', 6)\n",
    "# pd.set_options('max_rows', 10)\n",
    "# pd.reset_option('max_rows')\n",
    "# pd.set_option('max_colwidth', 10)\n",
    "# pd.set_option(\"chop_threshold\", 0.5)\n",
    "# pd.reset_option(\"chop_threshold\")\n",
    "# pd.set_option(\"colheader_justify\", \"left\")\n",
    "# pd.reset_option(\"colheader_justify\")\n",
    "# plt.rc('figure',figsize=(8,4))\n",
    "# plt.style.use('seaborn-whitegrid')\n",
    "# from IPython.display import display, Math, Latex\n",
    "# pio.renderers.default='plotly_mimetype'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-dialogue",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Data Loading</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floral-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_normal = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raised-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependents</th>\n",
       "      <th>prod_ct</th>\n",
       "      <th>mo_on_book</th>\n",
       "      <th>mo_inactive_r12</th>\n",
       "      <th>contr_ct_r12</th>\n",
       "      <th>revbal_avg_r12</th>\n",
       "      <th>credlim_avg_r12</th>\n",
       "      <th>opentobuy_avg_r12</th>\n",
       "      <th>utilratio_avg</th>\n",
       "      <th>tx_amt_r12</th>\n",
       "      <th>tx_ct_r12</th>\n",
       "      <th>chng_tx_amt_q4_q1</th>\n",
       "      <th>chng_tx_ct_q4_q1</th>\n",
       "      <th>marstat_Divorced</th>\n",
       "      <th>marstat_Married</th>\n",
       "      <th>marstat_Single</th>\n",
       "      <th>marstat_Unknown</th>\n",
       "      <th>card_Blue</th>\n",
       "      <th>card_Gold</th>\n",
       "      <th>card_Platinum</th>\n",
       "      <th>card_Silver</th>\n",
       "      <th>educ</th>\n",
       "      <th>inc</th>\n",
       "      <th>tx_amt_pertx_r12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>777.00</td>\n",
       "      <td>12,691.00</td>\n",
       "      <td>11,914.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1,144.00</td>\n",
       "      <td>42</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>864.00</td>\n",
       "      <td>8,256.00</td>\n",
       "      <td>7,392.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1,291.00</td>\n",
       "      <td>33</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,418.00</td>\n",
       "      <td>3,418.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,887.00</td>\n",
       "      <td>20</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>94.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   churn  age  gender  dependents  prod_ct  mo_on_book  mo_inactive_r12  \\\n",
       "0      0   45       1           3        5          39                1   \n",
       "1      0   49       0           5        6          44                1   \n",
       "2      0   51       1           3        4          36                1   \n",
       "\n",
       "   contr_ct_r12  revbal_avg_r12  credlim_avg_r12  opentobuy_avg_r12  \\\n",
       "0             3          777.00        12,691.00          11,914.00   \n",
       "1             2          864.00         8,256.00           7,392.00   \n",
       "2             0            0.00         3,418.00           3,418.00   \n",
       "\n",
       "   utilratio_avg  tx_amt_r12  tx_ct_r12  chng_tx_amt_q4_q1  chng_tx_ct_q4_q1  \\\n",
       "0           0.06    1,144.00         42               1.33              1.62   \n",
       "1           0.10    1,291.00         33               1.54              3.71   \n",
       "2           0.00    1,887.00         20               2.59              2.33   \n",
       "\n",
       "   marstat_Divorced  marstat_Married  marstat_Single  marstat_Unknown  \\\n",
       "0                 0                1               0                0   \n",
       "1                 0                0               1                0   \n",
       "2                 0                1               0                0   \n",
       "\n",
       "   card_Blue  card_Gold  card_Platinum  card_Silver  educ  inc  \\\n",
       "0          1          0              0            0     1    3   \n",
       "1          1          0              0            0     3    1   \n",
       "2          1          0              0            0     3    4   \n",
       "\n",
       "   tx_amt_pertx_r12  \n",
       "0             27.24  \n",
       "1             39.12  \n",
       "2             94.35  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-boxing",
   "metadata": {},
   "source": [
    "<a id='4.3'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Train Test Split</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerous-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_values = d.values\n",
    "x, y = d_values[:,1:], d_values[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-stockholm",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\"background-color:rgb(141, 153, 165);\n",
    "           font-size:250%;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 10px;\">Functions to Use</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-shadow",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_metrics(y_test, y_pred):\n",
    "    dic = {}\n",
    "    dic['accuracy'] = round(accuracy_score(y_test, y_pred), 2)\n",
    "    dic['precision'] = round(precision_score(y_test, y_pred), 2)\n",
    "    dic['recall'] = round(recall_score(y_test, y_pred), 2)\n",
    "    dic['f1'] = round(f1_score(y_test, y_pred), 2)\n",
    "    dic['f2'] = round(fbeta_score(y_test, y_pred, beta=2), 2)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-twist",
   "metadata": {},
   "source": [
    "### Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "serious-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_rskf(x, y, pipeline, mod_disp_name, n_splits=5, n_repeats=3):\n",
    "    scoring = {\n",
    "        'accuracy':'accuracy', 'precision':'precision', 'recall':'recall', 'f1':'f1', \n",
    "        'f2':make_scorer(fbeta_score, beta=2)} # dict val = scorer fct or predefined metric str  \n",
    "    cv = RepeatedStratifiedKFold(\n",
    "        n_splits=n_splits, n_repeats=n_repeats, random_state=1)       \n",
    "    result = cross_validate(\n",
    "        pipeline, x, y, cv=cv, \n",
    "        scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "        \n",
    "    # make a summary table\n",
    "    df = pd.DataFrame(\n",
    "        (k, mean(v), std(v)) for k,v in result.items()\n",
    "        ).rename({0:'metric', 1:'mean', 2:'std'}, axis=1\n",
    "                ).set_index('metric')\n",
    "    df.index.name = None\n",
    "    df.columns = pd.MultiIndex.from_product([[mod_disp_name],df.columns])\n",
    "    \n",
    "    return df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "apart-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_tts(x, y, pipeline, mod_disp_name):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)\n",
    "    time_0 = time()\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    time_1 = time()\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    time_2 = time()\n",
    "    result = {}\n",
    "    result['fit_time'] = round(time_1-time_0, 2)\n",
    "    result['score_time'] = round(time_2-time_1, 2)\n",
    "    result['accuracy'] = round(accuracy_score(y_test, y_pred), 2)\n",
    "    result['precision'] = round(precision_score(y_test, y_pred), 2)\n",
    "    result['recall'] = round(recall_score(y_test, y_pred), 2)\n",
    "    result['f1'] = round(f1_score(y_test, y_pred), 2)\n",
    "    result['f2'] = round(fbeta_score(y_test, y_pred, beta=2), 2)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "    df = pd.DataFrame(result, index=[mod_disp_name]).T\n",
    "    return df, result, conf_mat, y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "tutorial-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_full(models, scaler, set_applied='validation'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function\n",
    "    ----------\n",
    "    Returns a summary DataFrame of models and performance metrics\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list of tuples\n",
    "        List of tuples of model name and the instantiation of the \n",
    "        corresponding model for all models of interest\n",
    "    scaler : instantiation\n",
    "        Instantiation of scaler of interest\n",
    "    set_applied : str\n",
    "        'validation' by default. The other option is 'test'. \n",
    "        Any other text besides 'validation' works as 'test'.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results_summary_df : DataFrame\n",
    "        Summary DataFrame of all models and their performance metrics\n",
    "    names : list\n",
    "        List of model names\n",
    "    results : list of dictionaries containing all performance metrics\n",
    "        List of all performance metrics for each model\n",
    "    \"\"\"    \n",
    "    \n",
    "    # initiate results and scoring methods\n",
    "    results, names = [], []\n",
    "    scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "    \n",
    "    # define pipeline for all the models to try\n",
    "    for name, model in models:\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', scaler),\n",
    "            ('m', model)])\n",
    "        \n",
    "        # apply on validation sets\n",
    "        if set_applied=='validation':\n",
    "            cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)        \n",
    "            result = cross_validate(\n",
    "                pipeline, x_train, y_train, cv=cv, \n",
    "                scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "        \n",
    "        # apply on test sets\n",
    "        else:  \n",
    "            pipeline.fit(x_train, y_train)\n",
    "            y_pred = pipeline.predict(x_test)\n",
    "            result = perf_metrics(y_test, y_pred)  \n",
    "            \n",
    "        names.append(name)\n",
    "        results.append(result)    \n",
    "    \n",
    "    # make a summary table\n",
    "    results_summary_df = pd.DataFrame()\n",
    "    for i in np.arange(len(names)):\n",
    "        results_metric, results_mean, results_std = [], [], []\n",
    "        for k,v in results[i].items():\n",
    "            results_metric.append(k)\n",
    "            results_mean.append(np.round(np.mean(v),3))\n",
    "            results_std.append(np.round(np.std(v),3))\n",
    "            \n",
    "        if set_applied=='validation':\n",
    "            df = pd.DataFrame(\n",
    "                    list(zip(results_metric, results_mean, results_std, [names[i] for ct in np.arange(len(results[0]))])), \n",
    "                    columns=['metric', 'mean', 'std', 'mod'])\n",
    "            df = df.set_index(['mod','metric']).stack().unstack([1,2])\n",
    "            results_summary_df = pd.concat([results_summary_df, df])\n",
    "        else:\n",
    "            df = pd.DataFrame(\n",
    "                    list(zip(results_metric, results_mean, [names[i] for ct in np.arange(len(results[0]))])), \n",
    "                    columns=['metric', 'mean', 'mod'])\n",
    "            df = df.set_index(['mod','metric']).stack().unstack([1,2]).droplevel(1, axis=1) \n",
    "            results_summary_df = pd.concat([results_summary_df, df])        \n",
    "            \n",
    "            \n",
    "    return results_summary_df, names, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-warrant",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\"background-color:rgb(141, 153, 165);\n",
    "           font-size:250%;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 10px;\">Benchmark</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-cable",
   "metadata": {},
   "source": [
    "<a id='5.3.1'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        Comment on <code>MinMaxScaler()</code></h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-barcelona",
   "metadata": {},
   "source": [
    "The `MinMaxScaler()` transforms each feature individually by bounding the minimum and maximum values of each feature to a given range, usually `0` and `1`. If negative values exist, the scaler will bound the values to `-1` and `1`. This Scaler responds well if **the standard deviation is small** and when a **distribution is not Gaussian**. As this scaler is **sensitive to outliers**, it is important to treat outliers beforehand. We will see the effects of Outlier Treatment in a later section.\n",
    "\n",
    "[All About Feature Scaling, *Towards Data Science*](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)<br>\n",
    "[Standardize or Normalize Examples in Python, *Medium*](https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-challenge",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        Baseline Models</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "complimentary-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples for all models to explore: [(`model name`, `model instance`)] with minimum hyperparameter setting\n",
    "models = []\n",
    "\n",
    "# linear\n",
    "models.append(('LR', LogisticRegression(solver='saga', max_iter=10000, class_weight='balanced', random_state=5))) # note: `max_iter` from 1000 to 10000 due to convergence issues\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "# non-linear\n",
    "models.append(('DT', DecisionTreeClassifier(random_state=5)))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('MLP', MLPClassifier(max_iter=1000, random_state=5)))\n",
    "\n",
    "# ensemble\n",
    "models.append(('BDT', BaggingClassifier(n_estimators=50, n_jobs=-1, random_state=5)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=-1, random_state=5))) # note: increasing n_estimators more than 400 doesn't do much; some in place to prevent too much overfitting\n",
    "models.append(('GB', GradientBoostingClassifier(random_state=5))) # note: `max_iter` from 100 to 1000 due to convergence issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "affiliated-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of scaler to use\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-found",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Validation Set</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_baseline_validation = results_full(models, scaler, set_applied='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "signed-borough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fit_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">score_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>5.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>4.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>36.08</td>\n",
       "      <td>6.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric fit_time      score_time      test_accuracy      train_accuracy       \\\n",
       "           mean  std       mean  std          mean  std           mean  std   \n",
       "mod                                                                           \n",
       "LR         0.17 0.02       0.02 0.00          0.86 0.01           0.86 0.00   \n",
       "LDA        0.05 0.01       0.01 0.00          0.91 0.01           0.91 0.00   \n",
       "KNN        0.01 0.00       0.94 0.04          0.89 0.00           0.93 0.00   \n",
       "RF         5.60 0.68       1.13 0.32          0.96 0.00           0.99 0.00   \n",
       "NB         0.02 0.00       0.02 0.00          0.90 0.01           0.90 0.00   \n",
       "GB         4.04 0.08       0.03 0.00          0.96 0.00           0.97 0.00   \n",
       "MLP       36.08 6.03       0.02 0.00          0.94 0.01           0.96 0.01   \n",
       "\n",
       "metric test_precision      train_precision      test_recall      train_recall  \\\n",
       "                 mean  std            mean  std        mean  std         mean   \n",
       "mod                                                                             \n",
       "LR               0.54 0.02            0.54 0.00        0.86 0.02         0.86   \n",
       "LDA              0.77 0.02            0.78 0.01        0.62 0.04         0.63   \n",
       "KNN              0.72 0.03            0.89 0.00        0.48 0.02         0.67   \n",
       "RF               0.92 0.02            0.99 0.00        0.80 0.03         0.94   \n",
       "NB               0.71 0.03            0.71 0.01        0.59 0.04         0.59   \n",
       "GB               0.93 0.01            0.96 0.00        0.83 0.03         0.89   \n",
       "MLP              0.84 0.02            0.92 0.02        0.78 0.04         0.86   \n",
       "\n",
       "metric      test_f1      train_f1      test_roc_auc      train_roc_auc       \n",
       "        std    mean  std     mean  std         mean  std          mean  std  \n",
       "mod                                                                          \n",
       "LR     0.00    0.66 0.01     0.66 0.00         0.93 0.01          0.93 0.00  \n",
       "LDA    0.01    0.69 0.03     0.70 0.01         0.93 0.01          0.93 0.00  \n",
       "KNN    0.01    0.58 0.02     0.76 0.01         0.82 0.01          0.97 0.00  \n",
       "RF     0.01    0.85 0.01     0.96 0.00         0.99 0.00          1.00 0.00  \n",
       "NB     0.02    0.64 0.03     0.64 0.01         0.87 0.01          0.88 0.00  \n",
       "GB     0.00    0.88 0.01     0.92 0.00         0.99 0.00          0.99 0.00  \n",
       "MLP    0.03    0.81 0.02     0.89 0.02         0.97 0.00          0.99 0.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_baseline_validation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "current-penguin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">train_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric test_recall      train_recall     \n",
       "              mean  std         mean  std\n",
       "mod                                      \n",
       "LR            0.86 0.02         0.86 0.00\n",
       "LDA           0.62 0.04         0.63 0.01\n",
       "KNN           0.48 0.02         0.67 0.01\n",
       "RF            0.80 0.03         0.94 0.01\n",
       "NB            0.59 0.04         0.59 0.02\n",
       "GB            0.83 0.03         0.89 0.00\n",
       "MLP           0.78 0.04         0.86 0.03"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_baseline_validation[0][['test_recall', 'train_recall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-prairie",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Test Set</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-database",
   "metadata": {},
   "source": [
    "Gradient Boost and MLP on the test set saw some significant improvements compared to the those on the validation set due to informational gain. This makes sense because these models tend to be more sensitive to data size, and the validation set only uses 80% of the data (train set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "needed-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_baseline_test = results_full(models, scaler, set_applied='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "affected-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric  accuracy  precision  recall   f1   f2\n",
       "mod                                          \n",
       "LR          0.85       0.52    0.89 0.66 0.78\n",
       "LDA         0.92       0.79    0.67 0.72 0.69\n",
       "KNN         0.88       0.71    0.46 0.56 0.50\n",
       "RF          0.96       0.93    0.84 0.88 0.85\n",
       "NB          0.89       0.71    0.57 0.63 0.59\n",
       "GB          0.97       0.93    0.90 0.91 0.90\n",
       "MLP         0.95       0.86    0.83 0.85 0.84"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_baseline_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "careful-gallery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NB</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric  precision  recall   f2\n",
       "mod                           \n",
       "LR           0.52    0.89 0.78\n",
       "LDA          0.79    0.67 0.69\n",
       "KNN          0.71    0.46 0.50\n",
       "RF           0.93    0.84 0.85\n",
       "NB           0.71    0.57 0.59\n",
       "GB           0.93    0.90 0.90\n",
       "MLP          0.86    0.83 0.84"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_baseline_test[0][['precision','recall','f2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-syndicate",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Compare Algorithm</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-representative",
   "metadata": {},
   "source": [
    "We see some promising signs in Logistic Regression (`LR`), Random Forest (`RF`), Gradient Boost (`GB`), and Multilayer Perceptron (`MLP`) from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "organizational-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "names, results = r_baseline_validation[1], r_baseline_validation[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], label='No Skill', \n",
    "         marker='', linewidth=4, alpha=0.7, color='yellow')\n",
    "\n",
    "\n",
    "scaler = QuantileTransformer()\n",
    "\n",
    "# fit a model\n",
    "for i in np.arange(len(models)):\n",
    "    model = models[i][1]\n",
    "    pipeline = Pipeline([('s', scaler),('m',model)])\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # predict using test set\n",
    "    y_hat = pipeline.predict(x_test) # predict class values\n",
    "    y_hat_prob = pipeline.predict_proba(x_test)[:, 1] # predict probabilities; indexing added to retrieve just the probabilities for the positive class\n",
    "    \n",
    "    # print out the metrics for each model\n",
    "    precision, recall, f2, support = precision_recall_fscore_support(y_test, y_hat)\n",
    "    print('%s:   Precision: %.2f%%  Recall: %.2f%%  F-2: %.2f%%  Support: %.0f' % (\n",
    "    models[i][0], precision[1]*100, recall[1]*100, f2[1]*100, support[1]))\n",
    "\n",
    "    # compute precision-recall pairs for different probability thresholds & plot the results\n",
    "    precision_t, recall_t, _ = precision_recall_curve(y_test, y_hat_prob)\n",
    "    plt.plot(recall_t, precision_t, label=models[i][0],\n",
    "            marker='', linewidth=4, alpha=0.7)\n",
    "        \n",
    "# axis labels\n",
    "plt.xlabel('Recall', fontsize=18)\n",
    "plt.ylabel('Precision', fontsize=18)\n",
    "\n",
    "# show the legend\n",
    "plt.legend(loc = (0.15,0.25), fontsize=14)\n",
    "plt.title('2-Class Precision-Recall Curve',\n",
    "         fontsize=18, fontweight=2)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "welsh-period",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "\n",
    "plt.figure\n",
    "d_boxplot = [results[i]['test_recall'] for i in np.arange(len(results))]\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(d_boxplot)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-carry",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "<h2 style=\"background-color:rgb(141, 153, 165);\n",
    "           font-size:250%;\n",
    "           color:white;\n",
    "           text-align:center;\n",
    "           margin: auto;\n",
    "           padding: 10px;\">Scaling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-mistake",
   "metadata": {},
   "source": [
    "<a id='5.3.1'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        Comment on <code>StandardScaler()</code></h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-shopping",
   "metadata": {},
   "source": [
    "I have seen many kaggle submissions that default to `StandardScaler()` without the consideration of the data distribution. However, `StandardScaler()` assumes that **data is normally distributed** within each of the features and scales them such that the distribution is centered around $0$ with a standard deviation of $1$. If data is not normally distributed, `StandardScaler()` is not the best scaler to use. Therefore, we will not be using `StandardScaler()` before normalizing the data.\n",
    "\n",
    "[All About Feature Scaling, *Towards Data Science*](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)</br>\n",
    "[Selectively Scale Numerical Input Variables for Machine Learning, *Machine Learning Mastery*](https://machinelearningmastery.com/selectively-scale-numerical-input-variables-for-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-partnership",
   "metadata": {},
   "source": [
    "<a id='5.3.1'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        Comment on <code>RobustScaler()</code></h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-walker",
   "metadata": {},
   "source": [
    "`RobustScaler()` is robust to outliers as it does not use the standard summary statistics such as the mean and standard deviation for scaling. Instead, `RobustScaler()` removes the median and scales the data using the **quantile range** (defaults to IQR). Although the scaler is less affected by the outliers, it does not remove the outliers.\n",
    "\n",
    "[All About Feature Scaling, *Towards Data Science*](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)</br>\n",
    "[Standardize or Normalize Examples in Python, *Medium*](https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-jones",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Validation Set</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic_scaler_robust = results_validation(models, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaler_robust = results_summary_df(results_dic_scaler_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaler_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = result_scaler_robust.loc[:,['test_recall', 'train_recall']]\n",
    "df1['scaler']=scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index('scaler', append=True).unstack(1).reorder_levels(order=[2, 0, 1], axis=1).reindex(results_baseline.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = results_baseline.loc[:,['test_recall', 'train_recall']]\n",
    "df2['scaler']=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.set_index('scaler', append=True).unstack(1).reorder_levels(order=[2, 0, 1], axis=1).reindex(results_baseline.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-tulsa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-florence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-nutrition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "behind-killing",
   "metadata": {},
   "source": [
    "<a id='5.3.3'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Quantile Transformer Scaler</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-dispatch",
   "metadata": {},
   "source": [
    "`QuantileTransformer()` transforms the features to approximate a **uniform or a normal distribution** using **quantiles information**. Thus, the scaler spreads out the most frequent values as well as mitigate the effects of marginal outliers. This tranform is **non-linear**, so it may distort the features measured in the same scale but will help features measured in different scales more directly comparable. One can obtain a projection of the original values of a feature by using the cumulative distribution function. Another name for this scaler is the **Rank scaler**.\n",
    "\n",
    "[All About Feature Scaling, *Towards Data Science*](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = QuantileTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-print",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:120%;'>\n",
    "        Validation Set</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic_scaler_quant_transf = results_validation(models, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaler_quant_transf = results_summary_df(results_dic_scaler_quant_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaler_quant_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = result_scaler_quant_transf.loc[:,['test_recall', 'train_recall']]\n",
    "df1['scaler']=scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index('scaler', append=True).unstack(1).reorder_levels(order=[2, 0, 1], axis=1).reindex(results_baseline.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df3, df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-geometry",
   "metadata": {},
   "source": [
    "<a id='5.3.4'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Power Transformer Scaler</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-profession",
   "metadata": {},
   "source": [
    "The `PowerTransformer()` is a family of **parametric, monotonic** transformations that are applied to **make data more Gaussian-like**. This is useful for modeling issues related to the variability of a variable that is unequal across the range **(heteroscedasticity)** or situations where **normality is desired**.\n",
    "\n",
    "The power transform finds the optimal scaling factor in **stabilizing variance and minimizing skewness through maximum likelihood estimation**. Currently, Sklearn implementation of PowerTransformer supports the Box-Cox transform and the Yeo-Johnson transform. The optimal parameter for stabilizing variance and minimizing skewness is estimated through maximum likelihood. Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data.\n",
    "\n",
    "[Source: All About Feature Scaling](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = PowerTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-bradford",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:120%;'>\n",
    "        Validation Set</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic_scaler_pwr_transf = results_validation(models, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaler_pwr_transf = results_summary_df(results_dic_scaler_pwr_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaler_pwr_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = result_scaler_pwr_transf.loc[:,['test_recall', 'train_recall']]\n",
    "df1['scaler']=scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index('scaler', append=True).unstack(1).reorder_levels(order=[2, 0, 1], axis=1).reindex(results_baseline.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df3, df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-rolling",
   "metadata": {},
   "source": [
    "Going with Quantile Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-sunrise",
   "metadata": {},
   "source": [
    "# PR-AUC & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-environment",
   "metadata": {},
   "source": [
    "> However, ROC curves can present an overly optimistic view of an algorithmâ€™s performance if there is a large skew in the class distribution. [â€¦] Precision-Recall (PR) curves, often used in Information Retrieval , have been cited as an alternative to ROC curves for tasks with a large skew in the class distribution.\n",
    "\n",
    "â€” The Relationship Between Precision-Recall and ROC Curves, 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-houston",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:120%;'>\n",
    "        Plot</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-nancy",
   "metadata": {},
   "source": [
    "Some promising candidates are: `RF`, `GB`, and `MLP` with the current pipeline. This ranking may change with the addition of feature selection, extraction, possibly another outlier treatment, and resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision-recall curves\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], label='No Skill', \n",
    "         marker='', linewidth=4, alpha=0.7, color='yellow')\n",
    "\n",
    "\n",
    "scaler = QuantileTransformer()\n",
    "\n",
    "# fit a model\n",
    "for i in np.arange(len(models)):\n",
    "    model = models[i][1]\n",
    "    pipeline = Pipeline([('s', scaler),('m',model)])\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # predict using test set\n",
    "    y_hat = pipeline.predict(x_test) # predict class values\n",
    "    y_hat_prob = pipeline.predict_proba(x_test)[:, 1] # predict probabilities; indexing added to retrieve just the probabilities for the positive class\n",
    "    \n",
    "    # print out the metrics for each model\n",
    "    precision, recall, f2, support = precision_recall_fscore_support(y_test, y_hat)\n",
    "    print('%s:   Precision: %.2f%%  Recall: %.2f%%  F-2: %.2f%%  Support: %.0f' % (\n",
    "    models[i][0], precision[1]*100, recall[1]*100, f2[1]*100, support[1]))\n",
    "\n",
    "    # compute precision-recall pairs for different probability thresholds & plot the results\n",
    "    precision_t, recall_t, _ = precision_recall_curve(y_test, y_hat_prob)\n",
    "    plt.plot(recall_t, precision_t, label=models[i][0],\n",
    "            marker='', linewidth=4, alpha=0.7)\n",
    "        \n",
    "# axis labels\n",
    "plt.xlabel('Recall', fontsize=18)\n",
    "plt.ylabel('Precision', fontsize=18)\n",
    "\n",
    "# show the legend\n",
    "plt.legend(loc = (0.15,0.25), fontsize=14)\n",
    "plt.title('2-Class Precision-Recall Curve',\n",
    "         fontsize=18, fontweight=2)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "finish_normal = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished in {round(finish_normal-start_normal, 2)} second(s) or {round((finish_normal-start_normal)/60, 2)} minute(s).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-blast",
   "metadata": {},
   "source": [
    "Some promising candidates are: RF, GB, and MLP with the current pipelline. This ranking may change with the addition of feature selection / extraction and possibly another outlier treatment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
