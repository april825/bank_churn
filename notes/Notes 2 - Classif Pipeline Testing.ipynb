{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animal-chance",
   "metadata": {},
   "source": [
    "### Global Var Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_built_ins = dir()\n",
    "global_built_ins.append('global_built_ins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-klein",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "altered-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# statistics\n",
    "from numpy import (mean, std)\n",
    "\n",
    "# machine learning prep\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_validate, cross_val_predict,\n",
    "    StratifiedKFold, RepeatedStratifiedKFold)\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, fbeta_score, \n",
    "    confusion_matrix, make_scorer, SCORERS,\n",
    "    precision_recall_curve, plot_precision_recall_curve, \n",
    "    average_precision_score, precision_recall_fscore_support,\n",
    "    classification_report)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, IsolationForest)\n",
    "\n",
    "# warning\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# saving\n",
    "import os\n",
    "\n",
    "# efficiency\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "angry-bristol",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # general\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random as rd\n",
    "# import copy\n",
    "\n",
    "# # data visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# # statistics\n",
    "# from numpy import (mean, std)\n",
    "# from scipy import stats\n",
    "# from scipy.stats import (\n",
    "#     normaltest, anderson, jarque_bera,\n",
    "#     pearsonr, spearmanr, kendalltau,\n",
    "#     chi2_contingency, f_oneway)\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# # machine learning prep\n",
    "# from collections import Counter\n",
    "# from sklearn.preprocessing import (\n",
    "#     MinMaxScaler, RobustScaler, QuantileTransformer, PowerTransformer)\n",
    "# from sklearn.model_selection import (\n",
    "#     train_test_split, cross_validate, cross_val_score, cross_val_predict,\n",
    "#     RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV)\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score, precision_score, recall_score, f1_score, fbeta_score, auc, roc_auc_score,\n",
    "#     precision_recall_curve, plot_precision_recall_curve, average_precision_score, precision_recall_fscore_support,\n",
    "#     classification_report, precision_recall_fscore_support, confusion_matrix, make_scorer, SCORERS)\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # machine learning models\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import (GradientBoostingClassifier, IsolationForest)\n",
    "# from sklearn.svm import OneClassSVM\n",
    "\n",
    "# # warning\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "# warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# # saving\n",
    "# import os\n",
    "\n",
    "# # multiprocessing\n",
    "# import concurrent.futures\n",
    "# from time import time\n",
    "\n",
    "# # display settings\n",
    "# %matplotlib inline\n",
    "# pd.options.display.max_rows = 100\n",
    "# pd.options.display.max_columns = 100\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "# np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-durham",
   "metadata": {},
   "source": [
    "# Display Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "universal-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "synthetic-bracket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "/* CSS styles for pandas dataframe */\n",
       ".dataframe th {\n",
       "    font-size: 16px;\n",
       "}\n",
       ".dataframe td {\n",
       "    font-size: 14px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* CSS styles for pandas dataframe */\n",
    ".dataframe th {\n",
    "    font-size: 16px;\n",
    "}\n",
    ".dataframe td {\n",
    "    font-size: 14px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-sussex",
   "metadata": {},
   "source": [
    "### Global Var Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lucky-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_all = dir()\n",
    "global_libraries = [i for i in global_all if i not in global_built_ins] \n",
    "global_libraries.append('global_libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-pakistan",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "environmental-resident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependents</th>\n",
       "      <th>prod_ct</th>\n",
       "      <th>mo_on_book</th>\n",
       "      <th>mo_inactive_r12</th>\n",
       "      <th>contr_ct_r12</th>\n",
       "      <th>revbal_avg_r12</th>\n",
       "      <th>credlim_avg_r12</th>\n",
       "      <th>opentobuy_avg_r12</th>\n",
       "      <th>utilratio_avg</th>\n",
       "      <th>tx_amt_r12</th>\n",
       "      <th>tx_ct_r12</th>\n",
       "      <th>chng_tx_amt_q4_q1</th>\n",
       "      <th>chng_tx_ct_q4_q1</th>\n",
       "      <th>marstat_Divorced</th>\n",
       "      <th>marstat_Married</th>\n",
       "      <th>marstat_Single</th>\n",
       "      <th>marstat_Unknown</th>\n",
       "      <th>card_Blue</th>\n",
       "      <th>card_Gold</th>\n",
       "      <th>card_Platinum</th>\n",
       "      <th>card_Silver</th>\n",
       "      <th>educ</th>\n",
       "      <th>inc</th>\n",
       "      <th>tx_amt_pertx_r12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>777.00</td>\n",
       "      <td>12,691.00</td>\n",
       "      <td>11,914.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1,144.00</td>\n",
       "      <td>42</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>864.00</td>\n",
       "      <td>8,256.00</td>\n",
       "      <td>7,392.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1,291.00</td>\n",
       "      <td>33</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3,418.00</td>\n",
       "      <td>3,418.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1,887.00</td>\n",
       "      <td>20</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>94.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   churn  age  gender  dependents  prod_ct  mo_on_book  mo_inactive_r12  \\\n",
       "0      0   45       1           3        5          39                1   \n",
       "1      0   49       0           5        6          44                1   \n",
       "2      0   51       1           3        4          36                1   \n",
       "\n",
       "   contr_ct_r12  revbal_avg_r12  credlim_avg_r12  opentobuy_avg_r12  \\\n",
       "0             3          777.00        12,691.00          11,914.00   \n",
       "1             2          864.00         8,256.00           7,392.00   \n",
       "2             0            0.00         3,418.00           3,418.00   \n",
       "\n",
       "   utilratio_avg  tx_amt_r12  tx_ct_r12  chng_tx_amt_q4_q1  chng_tx_ct_q4_q1  \\\n",
       "0           0.06    1,144.00         42               1.33              1.62   \n",
       "1           0.10    1,291.00         33               1.54              3.71   \n",
       "2           0.00    1,887.00         20               2.59              2.33   \n",
       "\n",
       "   marstat_Divorced  marstat_Married  marstat_Single  marstat_Unknown  \\\n",
       "0                 0                1               0                0   \n",
       "1                 0                0               1                0   \n",
       "2                 0                1               0                0   \n",
       "\n",
       "   card_Blue  card_Gold  card_Platinum  card_Silver  educ  inc  \\\n",
       "0          1          0              0            0     1    3   \n",
       "1          1          0              0            0     3    1   \n",
       "2          1          0              0            0     3    4   \n",
       "\n",
       "   tx_amt_pertx_r12  \n",
       "0             27.24  \n",
       "1             39.12  \n",
       "2             94.35  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "canadian-apparel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int64'), dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm data consists only of numerical data types\n",
    "d.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-circulation",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "structured-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "d = d.values\n",
    "x, y = d[:,1:], d[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "herbal-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension: (10127, 26)\t Label Dimension: : (10127,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature Dimension: {x.shape}\\t Label Dimension: : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valued-antibody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Churn for the Full Data: 16.07%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of Churn for the Full Data: {round(y.sum()/len(y),4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sound-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Feature Dimension: (8101, 26)\t Train Label Dimension: : (8101,)\n",
      "Test Feature Dimension: (2026, 26)\t Test Label Dimension: : (2026,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Feature Dimension: {x_train.shape}\\t Train Label Dimension: : {y_train.shape}')\n",
    "print(f'Test Feature Dimension: {x_test.shape}\\t Test Label Dimension: : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "geographic-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Churn for the Train Set: 16.07%\n",
      "Percentage of Churn for the Test Set: 16.04%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Percentage of Churn for the Train Set: {round(y_train.sum()/len(y_train),4)*100}%\n",
    "Percentage of Churn for the Test Set: {round(y_test.sum()/len(y_test),4)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-township",
   "metadata": {},
   "source": [
    "# Model & Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satisfied-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "pipeline = Pipeline([('m', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-village",
   "metadata": {},
   "source": [
    "# Cross Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-tiger",
   "metadata": {},
   "source": [
    "### Using Repeated Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "original-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'accuracy':'accuracy', 'precision':'precision', 'recall':'recall', 'f1':'f1', \n",
    "    'f2':make_scorer(fbeta_score, beta=2)} # dict val = scorer fct or predefined metric str  \n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=10, n_repeats=5, random_state=1)       \n",
    "result = cross_validate(\n",
    "    pipeline, x, y, cv=cv, \n",
    "    scoring=scoring, return_train_score=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "least-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_disp_name = 'GB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "accessible-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 ms ± 715 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = pd.DataFrame((k, mean(v), std(v)) for k,v in result.items()\n",
    "                     ).rename({0:'metric', 1:'mean', 2:'std'}, axis=1\n",
    "                             ).set_index(['metric'])\n",
    "# df.columns = pd.MultiIndex.from_product([[mod_disp_name],df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "christian-royal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 ms ± 3.71 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df = pd.DataFrame(result).agg(['mean', 'std']).T\n",
    "# df.columns = pd.MultiIndex.from_product([[mod_disp_name],df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "specified-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "entitled-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>32.97</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f2</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean  std\n",
       "fit_time        32.97 2.75\n",
       "score_time       0.04 0.02\n",
       "test_accuracy    0.97 0.00\n",
       "train_accuracy   0.99 0.00\n",
       "test_precision   0.94 0.02\n",
       "train_precision  0.98 0.00\n",
       "test_recall      0.89 0.02\n",
       "train_recall     0.96 0.00\n",
       "test_f1          0.91 0.01\n",
       "train_f1         0.97 0.00\n",
       "test_f2          0.90 0.02\n",
       "train_f2         0.96 0.00"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "necessary-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    (k, mean(v), std(v)) for k,v in result.items()\n",
    "    ).rename({0:'metric', 1:'mean', 2:'std'}, axis=1\n",
    "            ).set_index('metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "african-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">GB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>32.97</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f2</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GB     \n",
       "                 mean  std\n",
       "fit_time        32.97 2.75\n",
       "score_time       0.04 0.02\n",
       "test_accuracy    0.97 0.00\n",
       "train_accuracy   0.99 0.00\n",
       "test_precision   0.94 0.02\n",
       "train_precision  0.98 0.00\n",
       "test_recall      0.89 0.02\n",
       "train_recall     0.96 0.00\n",
       "test_f1          0.91 0.01\n",
       "train_f1         0.97 0.00\n",
       "test_f2          0.90 0.02\n",
       "train_f2         0.96 0.00"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.name = None\n",
    "df.columns = pd.MultiIndex.from_product([[mod_disp_name],df.columns])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "muslim-defensive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">GB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>32.97</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_accuracy</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_precision</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_recall</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f1</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_f2</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GB     \n",
       "                 mean  std\n",
       "fit_time        32.97 2.78\n",
       "score_time       0.04 0.02\n",
       "test_accuracy    0.97 0.00\n",
       "train_accuracy   0.99 0.00\n",
       "test_precision   0.94 0.02\n",
       "train_precision  0.98 0.00\n",
       "test_recall      0.89 0.02\n",
       "train_recall     0.96 0.00\n",
       "test_f1          0.91 0.01\n",
       "train_f1         0.97 0.00\n",
       "test_f2          0.90 0.02\n",
       "train_f2         0.96 0.00"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-freight",
   "metadata": {},
   "source": [
    "### Multiindex Insert Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "subjective-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(np.random.rand(3), index=[\"a\",\"b\",\"c\"]).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abandoned-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = pd.MultiIndex.from_product([[\"new_label\"], df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "protecting-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(np.random.rand(3), index=[\"a\",\"b\",\"c\"]).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "upper-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0 0.16 0.44 0.61"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "noble-replica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('new_label', 'a'),\n",
       "            ('new_label', 'b'),\n",
       "            ('new_label', 'c')],\n",
       "           )"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.MultiIndex.from_product([[\"new_label\"], df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "under-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = pd.MultiIndex.from_product([[\"new_label\"], df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "local-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">new_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  new_label          \n",
       "          a    b    c\n",
       "0      0.16 0.44 0.61"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-tours",
   "metadata": {},
   "source": [
    "### Using Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diagnostic-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)        \n",
    "scoring = {'accuracy':'accuracy', 'precision':'precision', 'recall':'recall', 'f1':'f1', \n",
    "           'f2':make_scorer(fbeta_score, beta=2)}  # dict values can either be scorer functions or predefined metric strings.\n",
    "result = cross_validate(\n",
    "    pipeline, x_train, y_train, cv=cv, \n",
    "    scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "y_pred = cross_val_predict(pipeline, x_train, y_train, cv=cv)\n",
    "conf_mat = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-aerospace",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX - Small Set Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_test = y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-broadway",
   "metadata": {},
   "source": [
    "#### without the labels argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train_test, y_pred_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train_test, y_pred_test).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1 = 2*(recall*precision)/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-selling",
   "metadata": {},
   "source": [
    "#### with the labels argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train_test, y_pred_test, labels=[1,0])\n",
    "tp, fn, fp, tn = confusion_matrix(y_train_test, y_pred_test, labels=[1,0]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1 = 2*(recall*precision)/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-recipe",
   "metadata": {},
   "source": [
    "### CONFUSION MATRIX - Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "# (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-telling",
   "metadata": {},
   "source": [
    "#### without the labels argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1 = 2*(recall*precision)/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-veteran",
   "metadata": {},
   "source": [
    "#### with the labels argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_train, y_pred, labels=[1,0])\n",
    "tp, fn, fp, tn = confusion_matrix(y_train, y_pred, labels=[1,0]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tp, fn, fp, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = tp/(tp+fn)\n",
    "precision = tp/(tp+fp)\n",
    "f1 = 2*(recall*precision)/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-classroom",
   "metadata": {},
   "source": [
    "### Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result\n",
    "df = pd.DataFrame((k, mean(v), std(v)) for k,v in df.items()\n",
    "                     ).rename({0:'metric', 1:'mean', 2:'std'}, axis=1\n",
    "                             ).set_index(['metric'])\n",
    "df = df.loc[:, (df!=0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-aspect",
   "metadata": {},
   "source": [
    "# Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_0 = time()\n",
    "pipeline.fit(x_train, y_train)\n",
    "time_1 = time()\n",
    "y_pred = pipeline.predict(x_test)\n",
    "time_2 = time()\n",
    "result = {}\n",
    "result['fit_time'] = round(time_1-time_0, 2)\n",
    "result['score_time'] = round(time_2-time_1, 2)\n",
    "result['accuracy'] = round(accuracy_score(y_test, y_pred), 2)\n",
    "result['precision'] = round(precision_score(y_test, y_pred), 2)\n",
    "result['recall'] = round(recall_score(y_test, y_pred), 2)\n",
    "result['f1'] = round(f1_score(y_test, y_pred), 2)\n",
    "result['f2'] = round(fbeta_score(y_test, y_pred, beta=2), 2)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result\n",
    "df = pd.DataFrame((k, mean(v), std(v)) for k,v in df.items()\n",
    "                     ).rename({0:'metric', 1:'score', 2:'std'}, axis=1\n",
    "                             ).set_index(['metric'])\n",
    "df = df.loc[:,(df.sum()!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.loc[:,(np.sum(df)!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.loc[:,(df.sum()!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.loc[:, (df!=0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result\n",
    "df = pd.DataFrame((k, mean(v), std(v)) for k,v in df.items()\n",
    "                     ).rename({0:'metric', 1:'score', 2:'std'}, axis=1\n",
    "                             ).set_index(['metric'])\n",
    "df = df.loc[:, (df!=0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-rings",
   "metadata": {},
   "source": [
    "# Jason's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-shadow",
   "metadata": {},
   "source": [
    "[Source: Machine Learning Mastery - Nested Cross-Validation for Machine Learning with Python](https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-separation",
   "metadata": {},
   "source": [
    "## Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brief-industry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.927 (0.019)\n"
     ]
    }
   ],
   "source": [
    "# automatic nested cross-validation for random forest on a classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=1, n_informative=10, n_redundant=10)\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# define the model\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['n_estimators'] = [10, 100, 500]\n",
    "space['max_features'] = [2, 4, 6]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# execute the nested cross-validation\n",
    "scores = cross_val_score(search, X, y, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-praise",
   "metadata": {},
   "source": [
    "## Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual nested cross-validation for random forest on a classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=1, n_informative=10, n_redundant=10)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "\t# split data\n",
    "\tX_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "\ty_train, y_test = y[train_ix], y[test_ix]\n",
    "\t# configure the cross-validation procedure\n",
    "\tcv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\t# define the model\n",
    "\tmodel = RandomForestClassifier(random_state=1)\n",
    "\t# define search space\n",
    "\tspace = dict()\n",
    "\tspace['n_estimators'] = [10, 100, 500]\n",
    "\tspace['max_features'] = [2, 4, 6]\n",
    "\t# define search\n",
    "\tsearch = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "\t# execute search\n",
    "\tresult = search.fit(X_train, y_train)\n",
    "\t# get the best performing model fit on the whole training set\n",
    "\tbest_model = result.best_estimator_\n",
    "\t# evaluate model on the hold out dataset\n",
    "\tyhat = best_model.predict(X_test)\n",
    "\t# evaluate the model\n",
    "\tacc = accuracy_score(y_test, yhat)\n",
    "\t# store the result\n",
    "\touter_results.append(acc)\n",
    "\t# report progress\n",
    "\tprint('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-titanium",
   "metadata": {},
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-virginia",
   "metadata": {},
   "source": [
    "## vers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "disabled-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_results(pipeline, mod_disp_name, cv_method='rskf'):\n",
    "    \n",
    "    # apply on validation sets\n",
    "    if cv_method=='rskf': \n",
    "        scoring = {'accuracy':'accuracy', 'precision':'precision', 'recall':'recall', 'f1':'f1', \n",
    "                   'f2':make_scorer(fbeta_score, beta=2)} # dict val = scorer fct or predefined metric str  \n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, \n",
    "                                     random_state=1)       \n",
    "        result = cross_validate(\n",
    "            pipeline, x, y, cv=cv, \n",
    "            scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "        y_pred = cross_val_predict(\n",
    "            pipeline, x, y, cv=cv)\n",
    "        conf_mat = confusion_matrix(y, y_pred, labels=[1,0])\n",
    "\n",
    "    # apply on test sets\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)\n",
    "        time_0 = time()\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        time_1 = time()\n",
    "        y_pred = pipeline.predict(x_test)\n",
    "        time_2 = time()\n",
    "        result = {}\n",
    "        result['fit_time'] = round(time_1-time_0, 2)\n",
    "        result['score_time'] = round(time_2-time_1, 2)\n",
    "        result['accuracy'] = round(accuracy_score(y_test, y_pred), 2)\n",
    "        result['precision'] = round(precision_score(y_test, y_pred), 2)\n",
    "        result['recall'] = round(recall_score(y_test, y_pred), 2)\n",
    "        result['f1'] = round(f1_score(y_test, y_pred), 2)\n",
    "        result['f2'] = round(fbeta_score(y_test, y_pred, beta=2), 2)\n",
    "        conf_mat = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "    \n",
    "    # make a summary table\n",
    "    df = pd.DataFrame((k, mean(v), std(v)) for k,v in result.items()\n",
    "                         ).rename({0:'metric', 1:mod_disp_name, 2:'std'}, axis=1\n",
    "                                 ).set_index(['metric'])\n",
    "    df = df.loc[:,(df.sum()!=0)]\n",
    "            \n",
    "    return df, conf_mat, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-profession",
   "metadata": {},
   "source": [
    "<a id='6.1'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        Train-Test Split\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "final-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split train and test\n",
    "# d = d.values\n",
    "# x, y = d[:,1:], d[:,:1].ravel()\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advance-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Feature Dimension: {x.shape}\\t Label Dimension: : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "proof-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Percentage of Churn for the Full Data: {round(y.sum()/len(y),4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "healthy-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Train Feature Dimension: {x_train.shape}\\t Train Label Dimension: : {y_train.shape}')\n",
    "# print(f'Test Feature Dimension: {x_test.shape}\\t Test Label Dimension: : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "legal-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\"\"Peracentage of Churn for the Train Set: {round(y_train.sum()/len(y_train),4)*100}%\n",
    "# Percentage of Churn for the Test Set: {round(y_test.sum()/len(y_test),4)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_train_test_split(pipeline, mod_disp_name):\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)\n",
    "        time_0 = time()\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        time_1 = time()\n",
    "        y_pred = pipeline.predict(x_test)\n",
    "        time_2 = time()\n",
    "        result = {}\n",
    "        result['fit_time'] = round(time_1-time_0, 2)\n",
    "        result['score_time'] = round(time_2-time_1, 2)\n",
    "        result['accuracy'] = round(accuracy_score(y_test, y_pred), 2)\n",
    "        result['precision'] = round(precision_score(y_test, y_pred), 2)\n",
    "        result['recall'] = round(recall_score(y_test, y_pred), 2)\n",
    "        result['f1'] = round(f1_score(y_test, y_pred), 2)\n",
    "        result['f2'] = round(fbeta_score(y_test, y_pred, beta=2), 2)\n",
    "        conf_mat = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "    \n",
    "    # make a summary table\n",
    "    df = pd.DataFrame(result, index=[mod_disp_name]).T\n",
    "            \n",
    "    return df, conf_mat, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-evidence",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the modeling pipeline\n",
    "logit = LogisticRegression(class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "# scaler = MinMaxScaler() # logit requires scaling to behave somewhat more decently\n",
    "# pipeline = Pipeline([('s', scaler),('m', logit)])\n",
    "pipeline = Pipeline([('m', logit)])\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model\n",
    "m_scores = cross_validate(\n",
    "    pipeline, x_train, y_train, \n",
    "    scoring=['accuracy','precision','recall','f1'], \n",
    "    cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the results\n",
    "fit_time = round(mean(m_scores['fit_time']), 4)\n",
    "fit_time_sd = round(std(m_scores['fit_time']), 4)\n",
    "score_time = round(mean(m_scores['score_time']), 4)\n",
    "score_time_sd = round(std(m_scores['score_time']), 4)\n",
    "accuracy = round(mean(m_scores['test_accuracy']), 4)\n",
    "accuracy_sd = round(std(m_scores['test_accuracy']), 4)\n",
    "precision = round(mean(m_scores['test_precision']), 4)\n",
    "precision_sd = round(std(m_scores['test_precision']), 4)\n",
    "recall = round(mean(m_scores['test_recall']), 4)\n",
    "recall_sd = round(std(m_scores['test_recall']), 4)\n",
    "f1 = round(mean(m_scores['test_f1']), 4)\n",
    "f1_sd = round(std(m_scores['test_f1']), 4)\n",
    "\n",
    "print(\"\"\"Logistic Regression on Validation Set\n",
    "      Fit Time:\\t  %.2f (%.2f)\n",
    "      Score Time:  %.2f (%.2f)\n",
    "      Accuracy:\\t  %.2f (%.2f)%% \n",
    "      Precision:  %.2f (%.2f)%%  \n",
    "      Recall:\\t  %.2f (%.2f)%%  \n",
    "      F1 Score:\\t  %.2f (%.2f)%%\"\"\" \n",
    "      % (fit_time, fit_time_sd,\n",
    "         score_time, score_time_sd,\n",
    "         accuracy*100, accuracy_sd,\n",
    "         precision*100, precision_sd,\n",
    "         recall*100, recall_sd,\n",
    "         f1*100, f1_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test dataset\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions on test dataset\n",
    "accuracy = round(accuracy_score(y_test, y_pred), 4)\n",
    "precision = round(precision_score(y_test, y_pred), 4)\n",
    "recall = round(recall_score(y_test, y_pred), 4)\n",
    "f_1 = round(f1_score(y_test, y_pred), 4)\n",
    "f_2 = round(fbeta_score(y_test, y_pred, beta=2), 4)\n",
    "print(\"\"\"Logistic Regression on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to compare later\n",
    "baseline_logit = {\n",
    "    'accuracy' : round(accuracy*100,3),\n",
    "    'precision' : round(precision*100,3), \n",
    "    'recall' : round(recall*100,3), \n",
    "    'f1' : round(f_1*100,3), \n",
    "    'f2' : round(f_2*100,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Results')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-ready",
   "metadata": {},
   "source": [
    "<a id='6.3'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        Gradient Boosting Classifier\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-houston",
   "metadata": {},
   "source": [
    "For our emsemble baseline model we fit the XGBoost Classifier again without any feature selection or hyperparameter tuning. No normalization is necessary with this model since it is an ensemble of the tree methods. This means that removing outliers should not cause any material impact to the model's performance since the algorithm is not sensitive to monotonic transformations of its features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-upset",
   "metadata": {},
   "source": [
    "<a id='6.3.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Model Attributes\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting Classifier Parameters:\")\n",
    "GradientBoostingClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingClassifier_params = GradientBoostingClassifier().get_params()\n",
    "print(f\"\"\"Default Param Values:\n",
    "  `n_estimators`:\\t{GradientBoostingClassifier_params[\"n_estimators\"]} \n",
    "  `max_depth`:\\t\\t{GradientBoostingClassifier_params[\"max_depth\"]}\n",
    "  `learning_rate`:\\t{GradientBoostingClassifier_params[\"learning_rate\"]}\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-brother",
   "metadata": {},
   "source": [
    "<a id='6.3.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Model Fit & Evaluation\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# gb = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "# gb.fit(x_train, y_train)\n",
    "# y_pred = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.02 s ± 543 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the modeling pipeline\n",
    "gb = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model\n",
    "m_scores = cross_validate(\n",
    "    gb, x_train, y_train, \n",
    "    scoring=['accuracy','precision','recall','f1'], \n",
    "    cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the results\n",
    "fit_time = round(mean(m_scores['fit_time']), 4)\n",
    "fit_time_sd = round(std(m_scores['fit_time']), 4)\n",
    "score_time = round(mean(m_scores['score_time']), 4)\n",
    "score_time_sd = round(std(m_scores['score_time']), 4)\n",
    "accuracy = round(mean(m_scores['test_accuracy']), 4)\n",
    "accuracy_sd = round(std(m_scores['test_accuracy']), 4)\n",
    "precision = round(mean(m_scores['test_precision']), 4)\n",
    "precision_sd = round(std(m_scores['test_precision']), 4)\n",
    "recall = round(mean(m_scores['test_recall']), 4)\n",
    "recall_sd = round(std(m_scores['test_recall']), 4)\n",
    "f1 = round(mean(m_scores['test_f1']), 4)\n",
    "f1_sd = round(std(m_scores['test_f1']), 4)\n",
    "\n",
    "print(\"\"\"Gradient Boosting Classifier on Validation Set\n",
    "      Fit Time:\\t  %.2f (%.2f)\n",
    "      Score Time:  %.2f (%.2f)\n",
    "      Accuracy:\\t  %.2f (%.2f)%% \n",
    "      Precision:  %.2f (%.2f)%%  \n",
    "      Recall:\\t  %.2f (%.2f)%%  \n",
    "      F1 Score:\\t  %.2f (%.2f)%%\"\"\" \n",
    "      % (fit_time, fit_time_sd,\n",
    "         score_time, score_time_sd,\n",
    "         accuracy*100, accuracy_sd,\n",
    "         precision*100, precision_sd,\n",
    "         recall*100, recall_sd,\n",
    "         f1*100, f1_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test dataset\n",
    "gb.fit(x_train, y_train)\n",
    "y_pred = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions on test dataset\n",
    "accuracy = round(accuracy_score(y_test, y_pred), 4)\n",
    "precision = round(precision_score(y_test, y_pred), 4)\n",
    "recall = round(recall_score(y_test, y_pred), 4)\n",
    "f_1 = round(f1_score(y_test, y_pred), 4)\n",
    "f_2 = round(fbeta_score(y_test, y_pred, beta=2), 4)\n",
    "print(\"\"\"Gradient Boosting Classifier on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to compare later\n",
    "baseline_gb = {\n",
    "    'accuracy' : round(accuracy*100,3),\n",
    "    'precision' : round(precision*100,3), \n",
    "    'recall' : round(recall*100,3), \n",
    "    'f1' : round(f_1*100,3), \n",
    "    'f2' : round(f_2*100,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Results')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-mountain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
