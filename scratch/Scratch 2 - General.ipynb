{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "postal-campus",
   "metadata": {},
   "source": [
    "<a id='4.4.1.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Train-Test Split</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x, y = d[:,1:], d[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exposed-breeding",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension: (10127, 26)\t Label Dimension: : (10127,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Feature Dimension: {x.shape}\\t Label Dimension: : {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wicked-segment",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Churn for the Full Data: 16.07%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of Churn for the Full Data: {round(y.sum()/len(y),4)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "selected-philippines",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Feature Dimension: (8101, 26)\t Train Label Dimension: : (8101,)\n",
      "Test Feature Dimension: (2026, 26)\t Test Label Dimension: : (2026,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Feature Dimension: {x_train.shape}\\t Train Label Dimension: : {y_train.shape}')\n",
    "print(f'Test Feature Dimension: {x_test.shape}\\t Test Label Dimension: : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alike-howard",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Churn for Train Set: 16.07%\n",
      "Percentage of Churn for Test Set: 16.04%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Percentage of Churn for Train Set: {round(y_train.sum()/len(y_train),4)*100}%\n",
    "Percentage of Churn for Test Set: {round(y_test.sum()/len(y_test),4)*100}%\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-electricity",
   "metadata": {},
   "source": [
    "<a id='4.4.3'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Logistic Regression</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-jumping",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/selectively-scale-numerical-input-variables-for-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-placement",
   "metadata": {},
   "source": [
    "<a id='4.4.4'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Model Attributes</h2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "julian-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Logistic Regression Parameters:\")\n",
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "patient-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Param Values:\n",
      "  `C`:\t\t1.0 \n",
      "  `solver`:\tlbfgs\n",
      "  `max_iter`:\t100\n",
      "     \n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_params = LogisticRegression().get_params()\n",
    "print(f\"\"\"Default Param Values:\n",
    "  `C`:\\t\\t{LogisticRegression_params[\"C\"]} \n",
    "  `solver`:\\t{LogisticRegression_params[\"solver\"]}\n",
    "  `max_iter`:\\t{LogisticRegression_params[\"max_iter\"]}\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-violation",
   "metadata": {},
   "source": [
    "<a id='4.4.5'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Model Fitting & Evaluation - Baseline</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-spencer",
   "metadata": {},
   "source": [
    "Notes on L1 and L2 regularization:\n",
    "> *Inroducing a penalty to the sum of the weights means that the model has to \"distribute\" its weights optimally, so naturally most of this \"resource\" will go to the simple features that explain most of the variance, with complex features getting small or zero weights.*\n",
    "\n",
    "[Edden Gerber, *Comment on a Medium Article*](https://medium.com/@edden.gerber/thanks-for-the-article-1003ad7478b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "naval-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the modeling pipeline\n",
    "model = LogisticRegression(solver='saga', class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "scaler = MinMaxScaler()\n",
    "pipeline = Pipeline([('s',scaler),('m',model)])\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate the model\n",
    "m_scores = cross_validate(\n",
    "    pipeline, x_train, y_train, \n",
    "    scoring=['accuracy','precision','recall','f1'], cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "technical-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on Validation Set\n",
      "      Fit Time:\t  0.18 (0.03)\n",
      "      Score Time:  0.01 (0.01)\n",
      "      Accuracy:\t  84.68 (0.01)% \n",
      "      Precision:  51.54 (0.02)%  \n",
      "      Recall:\t  83.67 (0.04)%  \n",
      "      F1 Score:\t  63.73 (0.02)%\n"
     ]
    }
   ],
   "source": [
    "# summarize the results\n",
    "fit_time = round(mean(m_scores['fit_time']), 4)\n",
    "fit_time_sd = round(std(m_scores['fit_time']), 4)\n",
    "score_time = round(mean(m_scores['score_time']), 4)\n",
    "score_time_sd = round(std(m_scores['score_time']), 4)\n",
    "accuracy = round(mean(m_scores['test_accuracy']), 4)\n",
    "accuracy_sd = round(std(m_scores['test_accuracy']), 4)\n",
    "precision = round(mean(m_scores['test_precision']), 4)\n",
    "precision_sd = round(std(m_scores['test_precision']), 4)\n",
    "recall = round(mean(m_scores['test_recall']), 4)\n",
    "recall_sd = round(std(m_scores['test_recall']), 4)\n",
    "f1 = round(mean(m_scores['test_f1']), 4)\n",
    "f1_sd = round(std(m_scores['test_f1']), 4)\n",
    "\n",
    "print(\"\"\"Logistic Regression on Validation Set\n",
    "      Fit Time:\\t  %.2f (%.2f)\n",
    "      Score Time:  %.2f (%.2f)\n",
    "      Accuracy:\\t  %.2f (%.2f)%% \n",
    "      Precision:  %.2f (%.2f)%%  \n",
    "      Recall:\\t  %.2f (%.2f)%%  \n",
    "      F1 Score:\\t  %.2f (%.2f)%%\"\"\" \n",
    "      % (fit_time, fit_time_sd,\n",
    "         score_time, score_time_sd,\n",
    "         accuracy*100, accuracy_sd,\n",
    "         precision*100, precision_sd,\n",
    "         recall*100, recall_sd,\n",
    "         f1*100, f1_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "norman-concrete",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# model = LogisticRegression(solver='saga', class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "# Logistic Regression on Validation Set\n",
    "#       Fit Time:\t  0.18 (0.03)\n",
    "#       Score Time:  0.01 (0.01)\n",
    "#       Accuracy:\t  84.68 (0.01)% \n",
    "#       Precision:  51.54 (0.02)%  \n",
    "#       Recall:\t  83.67 (0.04)%  \n",
    "#       F1 Score:\t  63.73 (0.02)%\n",
    "\n",
    "# model = LogisticRegression(solver='saga', class_weight='balanced', C=0.01, max_iter=10000, random_state=1)\n",
    "# Logistic Regression on Validation Set\n",
    "#       Fit Time:\t  0.18 (0.02)\n",
    "#       Score Time:  0.01 (0.00)\n",
    "#       Accuracy:\t  80.66 (0.01)% \n",
    "#       Precision:  44.24 (0.02)%  \n",
    "#       Recall:\t  78.09 (0.05)%  \n",
    "#       F1 Score:\t  56.45 (0.02)%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "brilliant-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test dataset\n",
    "model.fit(x_train, y_train)\n",
    "yhat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions on test dataset\n",
    "accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "precision = round(precision_score(y_test, yhat), 4)\n",
    "recall = round(recall_score(y_test, yhat), 4)\n",
    "f_1 = round(f1_score(y_test, yhat), 4)\n",
    "f_2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "print(\"\"\"Logistic Regression on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "negative-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(solver='saga', class_weight='balanced', C=0.1, max_iter=10000, random_state=1)\n",
    "# Logistic Regression on Test Set\n",
    "#       Accuracy:\t  79.12% \n",
    "#       Precision:  42.17%  \n",
    "#       Recall:\t  81.23%  \n",
    "#       F1 Score:\t  55.52%\n",
    "#       F2 Score:\t  68.54%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "rental-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1339  362]\n",
      " [  61  264]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "impressive-choice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.79      0.86      1701\n",
      "         1.0       0.42      0.81      0.56       325\n",
      "\n",
      "    accuracy                           0.79      2026\n",
      "   macro avg       0.69      0.80      0.71      2026\n",
      "weighted avg       0.87      0.79      0.81      2026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Use RandomSearchCV to tune parameters for ISO\n",
    "\n",
    "# Takes a while to compute and uses a lot of CPU \n",
    "# https://stats.stackexchange.com/questions/186182/a-way-to-maintain-classifiers-recall-while-improving-precision\n",
    "#model\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "print('Running RandomizedSearchCV')\n",
    "# default IsolationForest but set random_state = 0 to keep consistent results\n",
    "iso = IsolationForest(random_state=123)\n",
    "\n",
    "# Implement RandomSearchCV\n",
    "\n",
    "# Number of trees in random forest [100, 150,..., 500]\n",
    "n_estimators = [int(x) for x in np.arange(start = 100, stop = 501, step = 50)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.arange(start = 1, stop = x_train.shape[1]+1, step = 1)]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "scoreFunction = {\"recall\": \"recall\"}\n",
    "\n",
    "# run a RandomizedSearchCV with 3 folds and 25 iterations \n",
    "random_search = RandomizedSearchCV(iso,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   n_iter = 25,\n",
    "                                   scoring = scoreFunction,               \n",
    "                                   refit = \"recall\",\n",
    "                                   return_train_score = False,\n",
    "                                   random_state = 0,\n",
    "                                   verbose = 2,\n",
    "                                   cv = 5,\n",
    "                                   n_jobs = -1) \n",
    "\n",
    "# trains and optimizes the model\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "print('Finished RandomizedSearchCV ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Improved Model from RandomizedSearchCV\")\n",
    "iso_search = random_search.best_estimator_\n",
    "iso_search.set_params(random_state=0)\n",
    "print(iso_search.get_params())\n",
    "evaluate(iso_search,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-stress",
   "metadata": {},
   "source": [
    "<a id='7.1.2.1'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Gradient Boosting Classifier\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-disclosure",
   "metadata": {},
   "source": [
    "<a id='7.1.2.2'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Logistic Regression\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-strike",
   "metadata": {},
   "source": [
    "<a id='7.2'>\n",
    "    <h2 style='font-size:210%;'>\n",
    "        One-Class SVM\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-qatar",
   "metadata": {},
   "source": [
    "The SVM algorithm originally developed for binary classification also has a use for detecting outliers. When modeling one class, the algorithm calculates the probability density function of the majority class and marks exmples on both extremes of the function as outliers. The class provides the argument `nu` which is equivalent of the percentage of outliers just like the argument `contamination` in `iso()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-australian",
   "metadata": {},
   "source": [
    "The main difference from a standard SVM is that One-Class SVM takes an unsupervised approach as it does not provide normal hyperparameters for tuning the margin like C. Instead, the argument `nu` is used to control the sensitivity of the support vectors and define the percentage of outliers just like the argument `contamination` in `iso()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-portsmouth",
   "metadata": {},
   "source": [
    "<a id='7.2.1'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Fit on All Classes\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-flexibility",
   "metadata": {},
   "source": [
    "<h2 style='font-size:150%;'>\n",
    "    Train-Test Split\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "clinical-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "graphic-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "tough-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8101, 26) (8101,)\n",
      "(2026, 26) (2026,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-photography",
   "metadata": {},
   "source": [
    "<h2 style='font-size:150%;'>\n",
    "    Model Attributes\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "devoted-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cache_size': 200,\n",
       " 'coef0': 0.0,\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'nu': 0.5,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneClassSVM().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "acquired-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "ocsvm = OneClassSVM(nu=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "noted-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = ocsvm.fit_predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "preliminary-walter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8101"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "instrumental-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8101, 26) (8101,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "primary-beads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8022, 26) (8022,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = x_train[yhat!=-1,:], y_train[yhat!=-1]\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "theoretical-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990248117516356"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)/8101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "injured-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2026,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-regulation",
   "metadata": {},
   "source": [
    "<a id='7.2.1.1'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Gradient Boosting Classifier\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rd.seed(1)\n",
    "gb = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "gb.fit(x_train, y_train)\n",
    "yhat = gb.predict(x_test)\n",
    "accuracy = round(accuracy_score(y_test, yhat), 3)\n",
    "precision = round(precision_score(y_test, yhat), 3)\n",
    "recall = round(recall_score(y_test, yhat), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "specific-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.seed(1)\n",
    "gb = GradientBoostingClassifier(n_estimators=300, max_depth=3, learning_rate=0.1)\n",
    "gb.fit(x_train, y_train)\n",
    "yhat = gb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "conscious-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier on Test Set\n",
      "      Accuracy:\t  97.98% \n",
      "      Precision:  94.10%  \n",
      "      Recall:\t  93.23%  \n",
      "      F1 Score:\t  93.66%\n",
      "      F2 Score:\t  93.40%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions on test dataset\n",
    "accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "precision = round(precision_score(y_test, yhat), 4)\n",
    "recall = round(recall_score(y_test, yhat), 4)\n",
    "f_1 = round(f1_score(y_test, yhat), 4)\n",
    "f_2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "print(\"\"\"Gradient Boosting Classifier on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100, \n",
    "         f_1*100, f_2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-affect",
   "metadata": {},
   "source": [
    "***Note:***\n",
    "\n",
    "* The baseline model yielded:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.972 / Precision: 0.93 / Recall: 0.895\n",
    "* `iso()` with 5% contamination yielded results slightly better results overall:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.974 / Precision: 0.939 / Recall: 0.898\n",
    "* `LocalOutlierFactor()` with no hyperparameter tuning:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.974 / Precision: 0.939 / Recall: 0.898\n",
    "* `OneClassSVM()` with nu = 0.05, 0.03, 0.01:\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.971 / Precision: 0.929 / Recall: 0.886\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.972 / Precision: 0.935 / Recall: 0.886\n",
    "    * Gradient Boosting Classifier -- Accuracy: 0.973 / Precision: 0.936 / Recall: 0.895"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-teens",
   "metadata": {},
   "source": [
    "<a id='7.1.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Fit on Majority Class\n",
    "    </h2>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-traffic",
   "metadata": {},
   "source": [
    "ignore the task of discrimination and instead focus on deviations from normal or what is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-irrigation",
   "metadata": {},
   "source": [
    "This solution has proven to be especially useful when the minority class lack any structure, being predominantly composed of small disjuncts or noisy instances.\n",
    "\n",
    "[Page 139, Learning from Imbalanced Data Sets, 2018.](https://www.amazon.com/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-prescription",
   "metadata": {},
   "source": [
    "One must remember that the advantages of one-class classifiers come at a price of discarding all of available information about the majority class. Therefore, this solution should be used carefully and may not fit some specific applications.\n",
    "\n",
    "[Page 140, Learning from Imbalanced Data Sets, 2018.](https://www.amazon.com/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x, y = d[:,1:], d[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit only on existing customers (majority class)\n",
    "x_train = x_train[y_train==0]\n",
    "y_train = y_train[y_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark inliers = 1\n",
    "y_train[y_train==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark inliers = 1, outliers = -1\n",
    "y_test[y_test==1] = -1\n",
    "y_test[y_test==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine shape\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-thumb",
   "metadata": {},
   "source": [
    "<a id='4.2'>\n",
    "    <h2 style='font-size:180%;'>\n",
    "        Spearman's Rank Correlation</h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-employee",
   "metadata": {},
   "source": [
    "This statistical method quantifies the degree to which ranked variables are associated by a monotonic function, meaning an increasing or decreasing relationship. As a statistical hypothesis test, the method assumes that the samples are uncorrelated (fail to reject H0).\n",
    "\n",
    "[Source: Machine Learning Mastery - How to Calculate Nonparametric Rank Correlation in Python](https://machinelearningmastery.com/how-to-calculate-nonparametric-rank-correlation-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "separate-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_churn = d.rank().corr(method='spearman')['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "persistent-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient Using Spearman's Rank Correlation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "churn                1.00\n",
       "contr_ct_r12         0.19\n",
       "mo_inactive_r12      0.17\n",
       "opentobuy_avg_r12    0.03\n",
       "dependents           0.02\n",
       "marstat_Single       0.02\n",
       "age                  0.02\n",
       "mo_on_book           0.02\n",
       "card_Platinum        0.01\n",
       "marstat_Unknown      0.01\n",
       "educ                 0.01\n",
       "card_Gold            0.01\n",
       "card_Blue            0.00\n",
       "marstat_Divorced     0.00\n",
       "tx_amt_pertx_r12    -0.01\n",
       "card_Silver         -0.01\n",
       "inc                 -0.02\n",
       "marstat_Married     -0.02\n",
       "gender              -0.04\n",
       "credlim_avg_r12     -0.05\n",
       "chng_tx_amt_q4_q1   -0.10\n",
       "prod_ct             -0.15\n",
       "tx_amt_r12          -0.22\n",
       "utilratio_avg       -0.24\n",
       "revbal_avg_r12      -0.24\n",
       "chng_tx_ct_q4_q1    -0.31\n",
       "tx_ct_r12           -0.38\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Correlation Coefficient Using Spearman\\'s Rank Correlation')\n",
    "spearman_churn.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "apparent-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null: the two variables are correlated\n",
    "reject_h0 = {}\n",
    "failtoreject_h0 = {}\n",
    "for i in d.rank().columns:\n",
    "    coef, p = spearmanr(d[i], d['churn'])\n",
    "    if p >= 0.05:\n",
    "        failtoreject_h0[i] = [round(coef,3), round(p,3)]\n",
    "    else:\n",
    "        reject_h0[i] = [round(coef,3), round(p,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "disciplinary-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following variables are likely correlated to `churn`. We can safely reject H0: \n",
      "\n",
      "Variable             Coef            p-value   \n",
      "churn                1.0             0.0       \n",
      "gender               -0.037          0.0       \n",
      "dependents           0.021           0.035     \n",
      "prod_ct              -0.15           0.0       \n",
      "mo_inactive_r12      0.172           0.0       \n",
      "contr_ct_r12         0.189           0.0       \n",
      "revbal_avg_r12       -0.241          0.0       \n",
      "credlim_avg_r12      -0.051          0.0       \n",
      "opentobuy_avg_r12    0.028           0.006     \n",
      "utilratio_avg        -0.24           0.0       \n",
      "tx_amt_r12           -0.224          0.0       \n",
      "tx_ct_r12            -0.376          0.0       \n",
      "chng_tx_amt_q4_q1    -0.102          0.0       \n",
      "chng_tx_ct_q4_q1     -0.312          0.0       \n",
      "marstat_Married      -0.024          0.017     \n"
     ]
    }
   ],
   "source": [
    "print(f'The following variables are likely correlated to `churn`. We can safely reject H0: \\n')\n",
    "print(\"{:<20} {:<15} {:<10}\".format('Variable', 'Coef', 'p-value'))\n",
    "for k,v in reject_h0.items():\n",
    "    print(\"{:<20} {:<15} {:<10}\".format(k,v[0], v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# load data\n",
    "d = pd.read_csv('source/d_num.csv')\n",
    "d = d.values\n",
    "x = d[:,1:]\n",
    "y = d[:,:1].ravel()\n",
    "\n",
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "# create scaler\n",
    "scaler = QuantileTransformer()\n",
    "\n",
    "# fit scaler on data\n",
    "scaler.fit(x_train)\n",
    "\n",
    "# apply transform\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# inverse transform\n",
    "# inverse = scaler.inverse_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-document",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def result_summary(names, results):\n",
    "#     # create a dataframe of results\n",
    "#     d_results = pd.DataFrame()\n",
    "#     for i in np.arange(len(names)):\n",
    "#         results_metric = []\n",
    "#         results_mean = []\n",
    "#         results_std = []\n",
    "#         for k,v in results[i].items():\n",
    "#             results_metric.append(k)\n",
    "#             results_mean.append(np.round(np.mean(v),3))\n",
    "#             results_std.append(np.round(np.std(v),3))\n",
    "#         df = pd.DataFrame(\n",
    "#                 list(zip(results_metric, results_mean, results_std, [names[i] for ct in np.arange(len(cv_results))])), \n",
    "#                 columns=['metric', 'mean', 'std', 'mod'])\n",
    "#         df = df.set_index(['mod','metric']).stack().unstack([1,2])\n",
    "#         d_results = pd.concat([d_results, df])\n",
    "        \n",
    "#     # return a dataframe of results\n",
    "#     return(d_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_test, yhat):\n",
    "    dic = {}\n",
    "    accuracy = round(accuracy_score(y_test, yhat), 4)\n",
    "    precision = round(precision_score(y_test, yhat), 4)\n",
    "    recall = round(recall_score(y_test, yhat), 4)\n",
    "    f1 = round(f1_score(y_test, yhat), 4)\n",
    "    f2 = round(fbeta_score(y_test, yhat, beta=2), 4)\n",
    "    dic['accuracy'] = round(accuracy*100,2)\n",
    "    dic['precision'] = round(precision*100,2)\n",
    "    dic['recall'] = round(recall*100,2)\n",
    "    dic['f1'] = round(f1*100,2)\n",
    "    dic['f2'] = round(f2*100,2)\n",
    "    print(\"\"\"Results on Test Set\n",
    "      Accuracy:\\t  %.2f%% \n",
    "      Precision:  %.2f%%  \n",
    "      Recall:\\t  %.2f%%  \n",
    "      F1 Score:\\t  %.2f%%\n",
    "      F2 Score:\\t  %.2f%%\"\"\" \n",
    "      % (accuracy*100, precision*100, recall*100,\n",
    "         f1*100, f2*100))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([('s',MinMaxScaler()),('m',mod)])\n",
    "\n",
    "def predict_yhat(x_train, y_train, x_test, y_test, mod, scaler):\n",
    "    pipeline = Pipeline([('s', scaler),('m', mod)])\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    yhat = pipeline.predict(x_test)\n",
    "    result = results(y_test, yhat)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit\n",
    "mod=LogisticRegression()\n",
    "print(mod)\n",
    "pipeline = Pipeline([('s',MinMaxScaler()),('m',mod)])\n",
    "pipeline.fit(x_train, y_train)\n",
    "yhat = pipeline.predict(x_test)\n",
    "baseline_logit = results(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "mod=SVC()\n",
    "print(mod)\n",
    "pipeline = Pipeline([('s',MinMaxScaler()),('m',mod)])\n",
    "pipeline.fit(x_train, y_train)\n",
    "yhat = pipeline.predict(x_test)\n",
    "print_results(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "mod=GradientBoostingClassifier()\n",
    "print(mod)\n",
    "pipeline = Pipeline([('s',MinMaxScaler()),('m',mod)])\n",
    "pipeline.fit(x_train, y_train)\n",
    "yhat = pipeline.predict(x_test)\n",
    "print_results(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-settle",
   "metadata": {},
   "source": [
    "# PR-AUC & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "spectacular-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train & test set\n",
    "d_values = d.values\n",
    "x, y = d_values[:,1:], d_values[:,:1].ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "permanent-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "model = models[6][1]\n",
    "scaler = QuantileTransformer()\n",
    "pipeline = Pipeline([('s', scaler),('m',model)])\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "grave-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using test set\n",
    "y_hat = pipeline.predict(x_test) # predict class values\n",
    "y_hat_prob = pipeline.predict_proba(x_test)[:, 1] # predict probabilities; index added to retrieve just the probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "minimal-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average precision (AP) from prediction scores\n",
    "precision_mean = average_precision_score(y_test, y_hat_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "committed-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision, recall, F-measure and support for each class\n",
    "precision, recall, f2, support = precision_recall_fscore_support(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "elegant-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA:   Precision: 89.93%  Recall: 82.46%  F-2: 86.04%  Support: 325\n"
     ]
    }
   ],
   "source": [
    "print('%s:   Precision: %.2f%%  Recall: %.2f%%  F-2: %.2f%%  Support: %.0f' % (\n",
    "    models[1][0], precision[1]*100, recall[1]*100, f2[1]*100, support[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "united-genetics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA        Precision: 89.93% Recall: 0.82% 0.8603531300160514\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<10} Precision: {:.2f}% Recall: {:.2f}% {:<10}\".format(models[1][0], round(precision[1]*100,2), recall[1], f2[1], support[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "studied-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision-recall pairs for different probability thresholds\n",
    "precision_t, recall_t, _ = precision_recall_curve(y_test, y_hat_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "greenhouse-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute f1 and pr-auc\n",
    "f1_score = f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "operational-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_score = fbeta_score(y_test, y_hat, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "worldwide-restaurant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize scores\n",
    "# print('GB: f1=%.3f prauc=%.3f' % (f1_score, prauc))\n",
    "\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall_t, precision_t, marker='.', label='GB')\n",
    "\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "# show the legend\n",
    "plt.legend()\n",
    "plt.title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(precision_mean))\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_full(models, scaler, set_applied='validation'):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    ----------\n",
    "    Returns a dictionary of tuples of `model name` and a \n",
    "    dictionary of `metrics` for each model on the user-defined set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    set_applied : str\n",
    "        'validation' by default. The other option is 'test' or any other texts work as 'test'\n",
    "    models : list of tuples\n",
    "        List of tuples of all models of interest\n",
    "    scaler : instantiation\n",
    "        Instantiation of scaler of interest\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results_dic : dict\n",
    "        Dictionary of tuples of `model name` and a dictionary of `metrics` for each model\n",
    "    \"\"\"\n",
    "    results, names = [], []\n",
    "    scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "    for name, model in models:\n",
    "        pipeline = Pipeline([('scaler', scaler),('m', model)])\n",
    "        if set_applied=='validation':  # apply on validation sets\n",
    "            cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)        \n",
    "            results = cross_validate(\n",
    "                pipeline, x_train, y_train, cv=cv, \n",
    "                scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "        else:  # apply on test sets\n",
    "            pipeline.fit(x_train, y_train)\n",
    "            yhat = pipeline.predict(x_test)\n",
    "            results = perf_metrics(y_test, yhat)            \n",
    "        names.append(name)\n",
    "        results.append(results)            \n",
    "    results_dic = dict(zip(names, results))\n",
    "    return results_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_validation(models, scaler):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function\n",
    "    ----------\n",
    "    Returns a dictionary of tuples of `model name` and a \n",
    "    dictionary of `metrics` for each model on the validation set\n",
    "    (stratified 5-fold cross validation)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list of tuples\n",
    "        List of tuples of all models of interest\n",
    "    scaler : instantiation\n",
    "        Instantiation of scaler of interest\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results_dic : dict\n",
    "        Dictionary of tuples of `model name` and a dictionary of `metrics` for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "    for name, model in models:\n",
    "        pipeline = Pipeline([('scaler', scaler),('m', model)])\n",
    "        # apply on cross validation sets generated by Stratified K Fold\n",
    "        cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)        \n",
    "        cv_results = cross_validate(\n",
    "            pipeline, x_train, y_train, cv=cv, \n",
    "            scoring=scoring, return_train_score=True, n_jobs=-1)\n",
    "        # create a list of model names\n",
    "        names.append(name)\n",
    "        # create a list of dictionaries of all metrics for each model\n",
    "        results.append(cv_results)\n",
    "    results_dic = dict(zip(names, results))\n",
    "    return results_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_test(models, scaler):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function\n",
    "    ----------\n",
    "    Returns a dictionary of tuples of `model name` and a \n",
    "    dictionary of `metrics` for each model on the test set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list of tuples\n",
    "        List of tuples of all models of interest\n",
    "    scaler : instantiation\n",
    "        Instantiation of scaler of interest\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results_dic : dict\n",
    "        Dictionary of tuples of `model name` and a dictionary of `metrics` for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ('accuracy', 'precision', 'recall', 'f1', 'roc_auc')\n",
    "    for name, model in models:\n",
    "        pipeline = Pipeline([('scaler', scaler),('m', model)])\n",
    "        \n",
    "        pipeline.fit(x_train, y_train)\n",
    "        yhat = pipeline.predict(x_test)\n",
    "        test_metrics = perf_metrics(y_test, yhat)\n",
    "        # create a list of model names\n",
    "        names.append(name)\n",
    "        # create a list of dictionaries of all metrics for each model\n",
    "        results.append(test_metrics)\n",
    "    results_dic = dict(zip(names, results))\n",
    "    return results_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-youth",
   "metadata": {},
   "source": [
    "<a id='5.3.1'>\n",
    "    <h2 style='font-size:150%;'>\n",
    "        Comment on <code>MinMaxScaler()</code></h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-traffic",
   "metadata": {},
   "source": [
    "The `MinMaxScaler()` transforms each feature individually by bounding the minimum and maximum values of each feature to a given range, usually `0` and `1`. If negative values exist, the scaler will bound the values to `-1` and `1`. This Scaler responds well if **the standard deviation is small** and when a **distribution is not Gaussian**. As this scaler is **sensitive to outliers**, it is important to treat outliers beforehand. We will see the effects of Outlier Treatment in a later section.\n",
    "\n",
    "[All About Feature Scaling, *Towards Data Science*](https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35)<br>\n",
    "[Standardize or Normalize Examples in Python, *Medium*](https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
